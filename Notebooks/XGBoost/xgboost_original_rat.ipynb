{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "73f30633",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import xgboost as xgb\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GroupShuffleSplit, GroupKFold, StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "\n",
    "\n",
    "from hyperopt import fmin, tpe, hp, STATUS_OK, Trials\n",
    "from typing import Any, Dict, Union\n",
    "\n",
    "from yellowbrick import model_selection as ms\n",
    "from yellowbrick.model_selection import validation_curve\n",
    "\n",
    "from sklearn import metrics\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from boruta import BorutaPy\n",
    "from BorutaShap import BorutaShap, load_data\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "79e7f1fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "all_train_ids =  ['S7072', 'S7083','S7070', 'S7096', 'S7091', 'S7094', 'S7075', 'S7071','S7101', 'S7088'] \n",
    "all_test_ids = ['S7086', 'S7069', 'S7076', 'S7092', 'S7071'] \n",
    "\n",
    "train_ids = [ 'S7072', 'S7083','S7070', 'S7096', 'S7091', 'S7094', 'S7075', 'S7071','S7101', 'S7088'] \n",
    "test_ids = ['S7086', 'S7069','S7076', 'S7092', 'S7071'] \n",
    "all_training_ids = ['S7072', 'S7083','S7070', 'S7096', 'S7091', 'S7094', 'S7075', 'S7071','S7101', 'S7088',\n",
    "                   'S7086', 'S7069','S7076', 'S7092', 'S7071']\n",
    "\n",
    "\n",
    "gap_ids = ['S7063', 'S7064', 'S7069', 'S7072', 'S7075', 'S7076', 'S7088', 'S7092', 'S7094', 'S7096']\n",
    "wt_ids = ['S7068', 'S7070', 'S7071', 'S7074', 'S7083', 'S7086', 'S7091', 'S7098', 'S7101']\n",
    "\n",
    "all_ids = ['S7068', 'S7070', 'S7071', 'S7074', 'S7086', 'S7091', 'S7098', 'S7101',\n",
    "          'S7063', 'S7064', 'S7069', 'S7072', 'S7075', 'S7076', 'S7088', 'S7092', 'S7094', 'S7096']\n",
    "\n",
    "def determine_genotype(animal_id, wt_ids, gap_ids):\n",
    "    if animal_id in wt_ids:\n",
    "        return 0  # WT\n",
    "    elif animal_id in gap_ids:\n",
    "        return 1  # GAP\n",
    "    else:\n",
    "        return None  # In case the ID is not found in either list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7fdc4dcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "og_cv = pd.read_csv('/home/melissa/RESULTS/FINAL_MODEL/Rat/all_measures_xgboost.csv')\n",
    "# Apply the function to each row in the DataFrame and ensure the type is integer\n",
    "og_cv['Genotype'] = og_cv['Animal_ID'].apply(lambda x: determine_genotype(x, wt_ids, gap_ids)).astype('Int64')\n",
    "\n",
    "og_cv.drop(['Unnamed: 0'], axis = 1, inplace = True) # 'Animal_ID.1'], axis = 1, inplace = True)\n",
    "\n",
    "# Move 'Genotype' column to the first position\n",
    "cols = og_cv.columns.tolist()\n",
    "cols.insert(0, cols.pop(cols.index('Genotype')))\n",
    "og_cv = og_cv[cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5f357279",
   "metadata": {},
   "outputs": [],
   "source": [
    "og_cv.drop(['Unnamed: 0.1'],axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "136f6b2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S7068\n",
      "S7074\n",
      "S7098\n",
      "S7063\n",
      "S7064\n"
     ]
    }
   ],
   "source": [
    "for idx in all_ids:\n",
    "    if idx not in all_training_ids:\n",
    "        print(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4bdd4b78",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_train_ids =  ['S7094', 'S7092', 'S7071', 'S7101', 'S7083', 'S6069', 'S7091',\n",
    "                 'S7070', 'S7072'] # 'S7063', 'S7064',\n",
    "all_test_ids = ['S7088', 'S7076', 'S7068', 'S7086'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "508415a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_cv = og_cv[og_cv['Animal_ID'].isin(all_train_ids)]\n",
    "test_cv = og_cv[og_cv['Animal_ID'].isin(all_test_ids)]\n",
    "clean_train = train_cv.dropna()\n",
    "clean_test = test_cv.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5ada3592",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['S7063', 'S7064', 'S7068', 'S7069', 'S7070', 'S7071', 'S7072',\n",
       "       'S7074', 'S7075', 'S7076', 'S7083', 'S7086', 'S7088', 'S7091',\n",
       "       'S7092', 'S7094', 'S7098', 'S7101'], dtype=object)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(og_cv['Animal_ID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1709aad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = clean_train #.iloc[:, 3:]\n",
    "y_train = clean_train.iloc[:, 0]\n",
    "\n",
    "oversample = RandomOverSampler(sampling_strategy = 'minority')\n",
    "X_train_res, y_train_res = oversample.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0ba8becb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mot_Disp</th>\n",
       "      <th>Som_Disp</th>\n",
       "      <th>Vis_Disp</th>\n",
       "      <th>Mot_HFD</th>\n",
       "      <th>Som_HFD</th>\n",
       "      <th>Vis_HFD</th>\n",
       "      <th>Mot_Hurst</th>\n",
       "      <th>Som_Hurst</th>\n",
       "      <th>Vis_Hurst</th>\n",
       "      <th>Mot_CC_Delta</th>\n",
       "      <th>...</th>\n",
       "      <th>Somatosensory_wpli_beta</th>\n",
       "      <th>Soma_Motor_wpli_beta</th>\n",
       "      <th>Vis_Soma_wpli_beta</th>\n",
       "      <th>Vis_Mot_wpli_beta</th>\n",
       "      <th>Motor_wpli_gamma</th>\n",
       "      <th>Visual_wpli_gamma</th>\n",
       "      <th>Somatosensory_wpli_gamma</th>\n",
       "      <th>Soma_Motor_wpli_gamma</th>\n",
       "      <th>Vis_Soma_wpli_gamma</th>\n",
       "      <th>Vis_Mot_wpli_gamma</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.661363</td>\n",
       "      <td>2.785862</td>\n",
       "      <td>2.150858</td>\n",
       "      <td>1.289230</td>\n",
       "      <td>1.459179</td>\n",
       "      <td>1.339925</td>\n",
       "      <td>0.533680</td>\n",
       "      <td>0.699312</td>\n",
       "      <td>0.831409</td>\n",
       "      <td>0.871219</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008596</td>\n",
       "      <td>0.010105</td>\n",
       "      <td>0.007713</td>\n",
       "      <td>0.026935</td>\n",
       "      <td>0.040043</td>\n",
       "      <td>0.081950</td>\n",
       "      <td>0.016776</td>\n",
       "      <td>0.011867</td>\n",
       "      <td>0.021683</td>\n",
       "      <td>0.029383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.429339</td>\n",
       "      <td>2.654425</td>\n",
       "      <td>2.318230</td>\n",
       "      <td>1.253846</td>\n",
       "      <td>1.418100</td>\n",
       "      <td>1.299268</td>\n",
       "      <td>0.544955</td>\n",
       "      <td>0.669769</td>\n",
       "      <td>0.667256</td>\n",
       "      <td>0.941749</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005709</td>\n",
       "      <td>0.015654</td>\n",
       "      <td>0.024139</td>\n",
       "      <td>0.034376</td>\n",
       "      <td>0.074832</td>\n",
       "      <td>0.045422</td>\n",
       "      <td>0.017500</td>\n",
       "      <td>0.010454</td>\n",
       "      <td>0.010117</td>\n",
       "      <td>0.017889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.658870</td>\n",
       "      <td>2.795139</td>\n",
       "      <td>2.432361</td>\n",
       "      <td>1.240087</td>\n",
       "      <td>1.410382</td>\n",
       "      <td>1.296731</td>\n",
       "      <td>0.468645</td>\n",
       "      <td>0.641504</td>\n",
       "      <td>0.657416</td>\n",
       "      <td>0.949999</td>\n",
       "      <td>...</td>\n",
       "      <td>0.013875</td>\n",
       "      <td>0.017930</td>\n",
       "      <td>0.021488</td>\n",
       "      <td>0.040603</td>\n",
       "      <td>0.060764</td>\n",
       "      <td>0.074715</td>\n",
       "      <td>0.014750</td>\n",
       "      <td>0.012921</td>\n",
       "      <td>0.011004</td>\n",
       "      <td>0.025993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.605193</td>\n",
       "      <td>2.848420</td>\n",
       "      <td>2.350064</td>\n",
       "      <td>1.231849</td>\n",
       "      <td>1.407521</td>\n",
       "      <td>1.307727</td>\n",
       "      <td>0.479316</td>\n",
       "      <td>0.628615</td>\n",
       "      <td>0.735998</td>\n",
       "      <td>0.933113</td>\n",
       "      <td>...</td>\n",
       "      <td>0.020781</td>\n",
       "      <td>0.019961</td>\n",
       "      <td>0.022619</td>\n",
       "      <td>0.023381</td>\n",
       "      <td>0.105975</td>\n",
       "      <td>0.074585</td>\n",
       "      <td>0.016429</td>\n",
       "      <td>0.017279</td>\n",
       "      <td>0.013135</td>\n",
       "      <td>0.021204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.754251</td>\n",
       "      <td>2.773382</td>\n",
       "      <td>2.462278</td>\n",
       "      <td>1.273213</td>\n",
       "      <td>1.417891</td>\n",
       "      <td>1.288588</td>\n",
       "      <td>0.561474</td>\n",
       "      <td>0.679757</td>\n",
       "      <td>0.672432</td>\n",
       "      <td>0.809575</td>\n",
       "      <td>...</td>\n",
       "      <td>0.013371</td>\n",
       "      <td>0.027543</td>\n",
       "      <td>0.039065</td>\n",
       "      <td>0.050705</td>\n",
       "      <td>0.088848</td>\n",
       "      <td>0.059773</td>\n",
       "      <td>0.017393</td>\n",
       "      <td>0.015753</td>\n",
       "      <td>0.017164</td>\n",
       "      <td>0.029807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170445</th>\n",
       "      <td>2.541671</td>\n",
       "      <td>2.647560</td>\n",
       "      <td>2.404107</td>\n",
       "      <td>1.288690</td>\n",
       "      <td>1.477289</td>\n",
       "      <td>1.306768</td>\n",
       "      <td>0.676413</td>\n",
       "      <td>0.818577</td>\n",
       "      <td>0.722124</td>\n",
       "      <td>0.897745</td>\n",
       "      <td>...</td>\n",
       "      <td>0.039525</td>\n",
       "      <td>0.012600</td>\n",
       "      <td>0.007077</td>\n",
       "      <td>0.025083</td>\n",
       "      <td>0.075226</td>\n",
       "      <td>0.037644</td>\n",
       "      <td>0.032116</td>\n",
       "      <td>0.014051</td>\n",
       "      <td>0.012882</td>\n",
       "      <td>0.025147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170446</th>\n",
       "      <td>3.519077</td>\n",
       "      <td>3.466632</td>\n",
       "      <td>3.253483</td>\n",
       "      <td>1.663243</td>\n",
       "      <td>1.678917</td>\n",
       "      <td>1.650991</td>\n",
       "      <td>0.800037</td>\n",
       "      <td>0.793568</td>\n",
       "      <td>0.780376</td>\n",
       "      <td>0.823311</td>\n",
       "      <td>...</td>\n",
       "      <td>0.034116</td>\n",
       "      <td>0.028201</td>\n",
       "      <td>0.019058</td>\n",
       "      <td>0.081637</td>\n",
       "      <td>0.202138</td>\n",
       "      <td>0.134014</td>\n",
       "      <td>0.064911</td>\n",
       "      <td>0.043927</td>\n",
       "      <td>0.031343</td>\n",
       "      <td>0.102282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170447</th>\n",
       "      <td>2.477125</td>\n",
       "      <td>2.502028</td>\n",
       "      <td>2.514698</td>\n",
       "      <td>1.220531</td>\n",
       "      <td>1.237121</td>\n",
       "      <td>1.239661</td>\n",
       "      <td>0.542464</td>\n",
       "      <td>0.565619</td>\n",
       "      <td>0.574018</td>\n",
       "      <td>0.971210</td>\n",
       "      <td>...</td>\n",
       "      <td>0.037730</td>\n",
       "      <td>0.023440</td>\n",
       "      <td>0.023588</td>\n",
       "      <td>0.072838</td>\n",
       "      <td>0.189166</td>\n",
       "      <td>0.100003</td>\n",
       "      <td>0.052490</td>\n",
       "      <td>0.029407</td>\n",
       "      <td>0.025424</td>\n",
       "      <td>0.083486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170448</th>\n",
       "      <td>2.641053</td>\n",
       "      <td>2.442376</td>\n",
       "      <td>2.272033</td>\n",
       "      <td>1.342775</td>\n",
       "      <td>1.368784</td>\n",
       "      <td>1.330834</td>\n",
       "      <td>0.659179</td>\n",
       "      <td>0.691285</td>\n",
       "      <td>0.833200</td>\n",
       "      <td>0.833304</td>\n",
       "      <td>...</td>\n",
       "      <td>0.026754</td>\n",
       "      <td>0.011018</td>\n",
       "      <td>0.007417</td>\n",
       "      <td>0.014718</td>\n",
       "      <td>0.067324</td>\n",
       "      <td>0.071101</td>\n",
       "      <td>0.026842</td>\n",
       "      <td>0.011057</td>\n",
       "      <td>0.009914</td>\n",
       "      <td>0.025262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170449</th>\n",
       "      <td>1.081958</td>\n",
       "      <td>1.059952</td>\n",
       "      <td>1.036280</td>\n",
       "      <td>1.866310</td>\n",
       "      <td>1.866588</td>\n",
       "      <td>1.869101</td>\n",
       "      <td>1.289205</td>\n",
       "      <td>1.292701</td>\n",
       "      <td>1.411652</td>\n",
       "      <td>0.999177</td>\n",
       "      <td>...</td>\n",
       "      <td>0.020243</td>\n",
       "      <td>0.055640</td>\n",
       "      <td>0.038921</td>\n",
       "      <td>0.061774</td>\n",
       "      <td>0.228324</td>\n",
       "      <td>0.145013</td>\n",
       "      <td>0.028277</td>\n",
       "      <td>0.061021</td>\n",
       "      <td>0.052250</td>\n",
       "      <td>0.081775</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>170450 rows × 159 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Mot_Disp  Som_Disp  Vis_Disp   Mot_HFD   Som_HFD   Vis_HFD  Mot_Hurst  \\\n",
       "0       2.661363  2.785862  2.150858  1.289230  1.459179  1.339925   0.533680   \n",
       "1       2.429339  2.654425  2.318230  1.253846  1.418100  1.299268   0.544955   \n",
       "2       2.658870  2.795139  2.432361  1.240087  1.410382  1.296731   0.468645   \n",
       "3       2.605193  2.848420  2.350064  1.231849  1.407521  1.307727   0.479316   \n",
       "4       2.754251  2.773382  2.462278  1.273213  1.417891  1.288588   0.561474   \n",
       "...          ...       ...       ...       ...       ...       ...        ...   \n",
       "170445  2.541671  2.647560  2.404107  1.288690  1.477289  1.306768   0.676413   \n",
       "170446  3.519077  3.466632  3.253483  1.663243  1.678917  1.650991   0.800037   \n",
       "170447  2.477125  2.502028  2.514698  1.220531  1.237121  1.239661   0.542464   \n",
       "170448  2.641053  2.442376  2.272033  1.342775  1.368784  1.330834   0.659179   \n",
       "170449  1.081958  1.059952  1.036280  1.866310  1.866588  1.869101   1.289205   \n",
       "\n",
       "        Som_Hurst  Vis_Hurst  Mot_CC_Delta  ...  Somatosensory_wpli_beta  \\\n",
       "0        0.699312   0.831409      0.871219  ...                 0.008596   \n",
       "1        0.669769   0.667256      0.941749  ...                 0.005709   \n",
       "2        0.641504   0.657416      0.949999  ...                 0.013875   \n",
       "3        0.628615   0.735998      0.933113  ...                 0.020781   \n",
       "4        0.679757   0.672432      0.809575  ...                 0.013371   \n",
       "...           ...        ...           ...  ...                      ...   \n",
       "170445   0.818577   0.722124      0.897745  ...                 0.039525   \n",
       "170446   0.793568   0.780376      0.823311  ...                 0.034116   \n",
       "170447   0.565619   0.574018      0.971210  ...                 0.037730   \n",
       "170448   0.691285   0.833200      0.833304  ...                 0.026754   \n",
       "170449   1.292701   1.411652      0.999177  ...                 0.020243   \n",
       "\n",
       "        Soma_Motor_wpli_beta  Vis_Soma_wpli_beta  Vis_Mot_wpli_beta  \\\n",
       "0                   0.010105            0.007713           0.026935   \n",
       "1                   0.015654            0.024139           0.034376   \n",
       "2                   0.017930            0.021488           0.040603   \n",
       "3                   0.019961            0.022619           0.023381   \n",
       "4                   0.027543            0.039065           0.050705   \n",
       "...                      ...                 ...                ...   \n",
       "170445              0.012600            0.007077           0.025083   \n",
       "170446              0.028201            0.019058           0.081637   \n",
       "170447              0.023440            0.023588           0.072838   \n",
       "170448              0.011018            0.007417           0.014718   \n",
       "170449              0.055640            0.038921           0.061774   \n",
       "\n",
       "        Motor_wpli_gamma  Visual_wpli_gamma  Somatosensory_wpli_gamma  \\\n",
       "0               0.040043           0.081950                  0.016776   \n",
       "1               0.074832           0.045422                  0.017500   \n",
       "2               0.060764           0.074715                  0.014750   \n",
       "3               0.105975           0.074585                  0.016429   \n",
       "4               0.088848           0.059773                  0.017393   \n",
       "...                  ...                ...                       ...   \n",
       "170445          0.075226           0.037644                  0.032116   \n",
       "170446          0.202138           0.134014                  0.064911   \n",
       "170447          0.189166           0.100003                  0.052490   \n",
       "170448          0.067324           0.071101                  0.026842   \n",
       "170449          0.228324           0.145013                  0.028277   \n",
       "\n",
       "        Soma_Motor_wpli_gamma  Vis_Soma_wpli_gamma  Vis_Mot_wpli_gamma  \n",
       "0                    0.011867             0.021683            0.029383  \n",
       "1                    0.010454             0.010117            0.017889  \n",
       "2                    0.012921             0.011004            0.025993  \n",
       "3                    0.017279             0.013135            0.021204  \n",
       "4                    0.015753             0.017164            0.029807  \n",
       "...                       ...                  ...                 ...  \n",
       "170445               0.014051             0.012882            0.025147  \n",
       "170446               0.043927             0.031343            0.102282  \n",
       "170447               0.029407             0.025424            0.083486  \n",
       "170448               0.011057             0.009914            0.025262  \n",
       "170449               0.061021             0.052250            0.081775  \n",
       "\n",
       "[170450 rows x 159 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_borut = X_train_res.iloc[:, 3:]\n",
    "X_train_borut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6755345f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Animal_ID'], dtype='object')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_res.select_dtypes(include=['object', 'category']).columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "ef4f1d02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40fb22a655e7417dad61b6b977c008d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28 attributes confirmed important: ['Mot_Disp', 'Vis_HFD', 'Mot_HFD', 'Mot_CC_Beta', 'Mot_CC_Theta', 'Mot_CC_Sigma', 'Som_Disp', 'Som_CC_Theta', 'Som_CC_Sigma', 'Mot_Hurst', 'Vis_Disp', 'Vis_CC_Delta', 'Mot_Theta', 'Mot_CC_Delta', 'Vis_CC_Theta', 'Som_HFD', 'Mot_Delta', 'Som_CC_Beta', 'Som_CC_Delta', 'Vis_CC_Gamma', 'Mot_Gamma', 'Mot_CC_Gamma', 'Vis_CC_Beta', 'Vis_Hurst', 'Vis_CC_Sigma', 'Mot_Beta', 'Som_CC_Gamma', 'Som_Hurst']\n",
      "11 attributes confirmed unimportant: ['Vis_Beta', 'Som_Theta', 'Vis_Gamma', 'Vis_Theta', 'Som_Beta', 'Vis_Sigma', 'Vis_Delta', 'Som_Sigma', 'Som_Delta', 'Mot_Sigma', 'Som_Gamma']\n",
      "0 tentative attributes remains: []\n"
     ]
    }
   ],
   "source": [
    "estimator_borutashap=XGBClassifier(n_jobs = -1,\n",
    "                                           random_state=42,\n",
    "                                           max_depth=4)\n",
    "borutashap = BorutaShap(model = estimator_borutashap,\n",
    "                            importance_measure = 'shap',\n",
    "                            classification = True)\n",
    "borutashap.fit(X = X_train_borut, y = y_train_res, \n",
    "                   n_trials = 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "775bfe74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2000x1000 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "borutashap.plot(X_size=12, figsize=(20,10),\n",
    "            y_scale='log', which_features='tentative')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "47a45d93",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['Genotype', 'Animal_ID', 'Mot_Disp', 'Vis_HFD', 'Mot_HFD', \n",
    "            'Mot_CC_Beta', 'Mot_CC_Theta', 'Mot_CC_Sigma', 'Som_Disp', \n",
    "            'Som_CC_Theta', 'Som_CC_Sigma', 'Mot_Hurst', 'Vis_Disp',\n",
    "            'Vis_CC_Delta', 'Mot_Theta', 'Mot_CC_Delta', 'Vis_CC_Theta', \n",
    "            'Som_HFD', 'Mot_Delta', 'Som_CC_Beta', 'Som_CC_Delta', 'Vis_CC_Gamma',\n",
    "            'Mot_Gamma', 'Mot_CC_Gamma', 'Vis_CC_Beta', 'Vis_Hurst',\n",
    "            'Vis_CC_Sigma', 'Mot_Beta', 'Som_CC_Gamma', 'Som_Hurst']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "62c20550",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = og_cv[features]\n",
    "clean_df = new_df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1cb01d1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "247247\n",
      "247247\n"
     ]
    }
   ],
   "source": [
    "print(len(new_df))\n",
    "print(len(clean_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "457f6f75",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_train_ids =  ['S7071', 'S7068', 'S7091',  'S7092', 'S7063', 'S7088', 'S7101', 'S7064', 'S7083',\n",
    "                  'S7070',  'S7072', 'S7069', 'S7094'] \n",
    "all_test_ids = [ 'S7086', 'S7076'] \n",
    "X_train = clean_df[clean_df[\"Animal_ID\"].isin(all_train_ids)]\n",
    "X_test = clean_df[clean_df[\"Animal_ID\"].isin(all_test_ids)]\n",
    "y_train = X_train.iloc[:, 0]\n",
    "y_test = X_test.iloc[:, 0]\n",
    "\n",
    "oversample = RandomOverSampler(sampling_strategy = 'minority')\n",
    "X_train_res, y_train_res = oversample.fit_resample(X_train, y_train)\n",
    "X_test_res, y_test_res = oversample.fit_resample(X_test, y_test)\n",
    "X_test_new = X_test_res.iloc[:, 2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "232ca928",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Genotype</th>\n",
       "      <th>Animal_ID</th>\n",
       "      <th>Mot_Disp</th>\n",
       "      <th>Vis_HFD</th>\n",
       "      <th>Mot_HFD</th>\n",
       "      <th>Mot_CC_Beta</th>\n",
       "      <th>Mot_CC_Theta</th>\n",
       "      <th>Mot_CC_Sigma</th>\n",
       "      <th>Som_Disp</th>\n",
       "      <th>Som_CC_Theta</th>\n",
       "      <th>...</th>\n",
       "      <th>Som_CC_Delta</th>\n",
       "      <th>Vis_CC_Gamma</th>\n",
       "      <th>Mot_Gamma</th>\n",
       "      <th>Mot_CC_Gamma</th>\n",
       "      <th>Vis_CC_Beta</th>\n",
       "      <th>Vis_Hurst</th>\n",
       "      <th>Vis_CC_Sigma</th>\n",
       "      <th>Mot_Beta</th>\n",
       "      <th>Som_CC_Gamma</th>\n",
       "      <th>Som_Hurst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>25698</th>\n",
       "      <td>0</td>\n",
       "      <td>S7068</td>\n",
       "      <td>2.468089</td>\n",
       "      <td>1.531774</td>\n",
       "      <td>1.541066</td>\n",
       "      <td>0.848314</td>\n",
       "      <td>0.774044</td>\n",
       "      <td>0.804200</td>\n",
       "      <td>2.317283</td>\n",
       "      <td>0.981321</td>\n",
       "      <td>...</td>\n",
       "      <td>0.987070</td>\n",
       "      <td>0.932837</td>\n",
       "      <td>1.590701</td>\n",
       "      <td>0.850342</td>\n",
       "      <td>0.967545</td>\n",
       "      <td>0.956093</td>\n",
       "      <td>0.985163</td>\n",
       "      <td>3.047907</td>\n",
       "      <td>0.947320</td>\n",
       "      <td>0.960286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25699</th>\n",
       "      <td>0</td>\n",
       "      <td>S7068</td>\n",
       "      <td>3.400439</td>\n",
       "      <td>1.650820</td>\n",
       "      <td>1.605394</td>\n",
       "      <td>0.767537</td>\n",
       "      <td>0.808924</td>\n",
       "      <td>0.813156</td>\n",
       "      <td>3.331261</td>\n",
       "      <td>0.930799</td>\n",
       "      <td>...</td>\n",
       "      <td>0.806586</td>\n",
       "      <td>0.927611</td>\n",
       "      <td>1.904163</td>\n",
       "      <td>0.856906</td>\n",
       "      <td>0.938395</td>\n",
       "      <td>0.789157</td>\n",
       "      <td>0.923116</td>\n",
       "      <td>3.157070</td>\n",
       "      <td>0.941685</td>\n",
       "      <td>0.773338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25700</th>\n",
       "      <td>0</td>\n",
       "      <td>S7068</td>\n",
       "      <td>3.491144</td>\n",
       "      <td>1.594440</td>\n",
       "      <td>1.575696</td>\n",
       "      <td>0.755571</td>\n",
       "      <td>0.731160</td>\n",
       "      <td>0.698019</td>\n",
       "      <td>3.413144</td>\n",
       "      <td>0.963050</td>\n",
       "      <td>...</td>\n",
       "      <td>0.386298</td>\n",
       "      <td>0.934130</td>\n",
       "      <td>2.190386</td>\n",
       "      <td>0.850113</td>\n",
       "      <td>0.939114</td>\n",
       "      <td>0.651875</td>\n",
       "      <td>0.945212</td>\n",
       "      <td>3.018505</td>\n",
       "      <td>0.946289</td>\n",
       "      <td>0.689770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25701</th>\n",
       "      <td>0</td>\n",
       "      <td>S7068</td>\n",
       "      <td>3.522350</td>\n",
       "      <td>1.623913</td>\n",
       "      <td>1.581819</td>\n",
       "      <td>0.840038</td>\n",
       "      <td>0.779113</td>\n",
       "      <td>0.745105</td>\n",
       "      <td>3.362523</td>\n",
       "      <td>0.951927</td>\n",
       "      <td>...</td>\n",
       "      <td>0.680604</td>\n",
       "      <td>0.919053</td>\n",
       "      <td>1.671060</td>\n",
       "      <td>0.847344</td>\n",
       "      <td>0.916748</td>\n",
       "      <td>0.704243</td>\n",
       "      <td>0.904325</td>\n",
       "      <td>2.737714</td>\n",
       "      <td>0.937278</td>\n",
       "      <td>0.707645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25702</th>\n",
       "      <td>0</td>\n",
       "      <td>S7068</td>\n",
       "      <td>3.110243</td>\n",
       "      <td>1.639482</td>\n",
       "      <td>1.613143</td>\n",
       "      <td>0.872627</td>\n",
       "      <td>0.945476</td>\n",
       "      <td>0.872156</td>\n",
       "      <td>3.011952</td>\n",
       "      <td>0.941902</td>\n",
       "      <td>...</td>\n",
       "      <td>0.938718</td>\n",
       "      <td>0.915246</td>\n",
       "      <td>1.750019</td>\n",
       "      <td>0.896415</td>\n",
       "      <td>0.932768</td>\n",
       "      <td>0.928782</td>\n",
       "      <td>0.908092</td>\n",
       "      <td>2.212783</td>\n",
       "      <td>0.933922</td>\n",
       "      <td>0.852319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>215143</th>\n",
       "      <td>0</td>\n",
       "      <td>S7091</td>\n",
       "      <td>3.034338</td>\n",
       "      <td>1.322504</td>\n",
       "      <td>1.259085</td>\n",
       "      <td>0.921761</td>\n",
       "      <td>0.966436</td>\n",
       "      <td>0.971496</td>\n",
       "      <td>2.797163</td>\n",
       "      <td>0.970359</td>\n",
       "      <td>...</td>\n",
       "      <td>0.541272</td>\n",
       "      <td>0.841883</td>\n",
       "      <td>0.416426</td>\n",
       "      <td>0.860202</td>\n",
       "      <td>0.911593</td>\n",
       "      <td>0.651487</td>\n",
       "      <td>0.971595</td>\n",
       "      <td>2.572972</td>\n",
       "      <td>0.901995</td>\n",
       "      <td>0.667459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>215144</th>\n",
       "      <td>0</td>\n",
       "      <td>S7070</td>\n",
       "      <td>3.577321</td>\n",
       "      <td>1.532722</td>\n",
       "      <td>1.586918</td>\n",
       "      <td>0.927472</td>\n",
       "      <td>0.927472</td>\n",
       "      <td>0.927972</td>\n",
       "      <td>3.151484</td>\n",
       "      <td>0.936685</td>\n",
       "      <td>...</td>\n",
       "      <td>0.458749</td>\n",
       "      <td>0.698082</td>\n",
       "      <td>1.073763</td>\n",
       "      <td>0.906288</td>\n",
       "      <td>0.829179</td>\n",
       "      <td>0.822102</td>\n",
       "      <td>0.826608</td>\n",
       "      <td>2.479426</td>\n",
       "      <td>0.927068</td>\n",
       "      <td>0.754607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>215145</th>\n",
       "      <td>0</td>\n",
       "      <td>S7070</td>\n",
       "      <td>3.239876</td>\n",
       "      <td>1.475545</td>\n",
       "      <td>1.438272</td>\n",
       "      <td>0.936087</td>\n",
       "      <td>0.936087</td>\n",
       "      <td>0.929083</td>\n",
       "      <td>2.980007</td>\n",
       "      <td>0.921387</td>\n",
       "      <td>...</td>\n",
       "      <td>0.716545</td>\n",
       "      <td>0.729942</td>\n",
       "      <td>0.815211</td>\n",
       "      <td>0.918187</td>\n",
       "      <td>0.838981</td>\n",
       "      <td>0.755101</td>\n",
       "      <td>0.866693</td>\n",
       "      <td>2.067910</td>\n",
       "      <td>0.921572</td>\n",
       "      <td>0.745627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>215146</th>\n",
       "      <td>0</td>\n",
       "      <td>S7068</td>\n",
       "      <td>3.478297</td>\n",
       "      <td>1.473189</td>\n",
       "      <td>1.478744</td>\n",
       "      <td>0.765125</td>\n",
       "      <td>0.828053</td>\n",
       "      <td>0.734246</td>\n",
       "      <td>3.415379</td>\n",
       "      <td>0.923742</td>\n",
       "      <td>...</td>\n",
       "      <td>0.769699</td>\n",
       "      <td>0.910860</td>\n",
       "      <td>1.789152</td>\n",
       "      <td>0.750488</td>\n",
       "      <td>0.890407</td>\n",
       "      <td>0.426038</td>\n",
       "      <td>0.868962</td>\n",
       "      <td>8.968698</td>\n",
       "      <td>0.926244</td>\n",
       "      <td>0.647426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>215147</th>\n",
       "      <td>0</td>\n",
       "      <td>S7101</td>\n",
       "      <td>2.974162</td>\n",
       "      <td>1.366324</td>\n",
       "      <td>1.253978</td>\n",
       "      <td>0.882371</td>\n",
       "      <td>0.961603</td>\n",
       "      <td>0.961603</td>\n",
       "      <td>3.229786</td>\n",
       "      <td>0.931169</td>\n",
       "      <td>...</td>\n",
       "      <td>0.686241</td>\n",
       "      <td>0.479150</td>\n",
       "      <td>0.437639</td>\n",
       "      <td>0.870515</td>\n",
       "      <td>0.599465</td>\n",
       "      <td>0.612220</td>\n",
       "      <td>0.631981</td>\n",
       "      <td>2.091459</td>\n",
       "      <td>0.520276</td>\n",
       "      <td>0.582032</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>107574 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Genotype Animal_ID  Mot_Disp   Vis_HFD   Mot_HFD  Mot_CC_Beta  \\\n",
       "25698          0     S7068  2.468089  1.531774  1.541066     0.848314   \n",
       "25699          0     S7068  3.400439  1.650820  1.605394     0.767537   \n",
       "25700          0     S7068  3.491144  1.594440  1.575696     0.755571   \n",
       "25701          0     S7068  3.522350  1.623913  1.581819     0.840038   \n",
       "25702          0     S7068  3.110243  1.639482  1.613143     0.872627   \n",
       "...          ...       ...       ...       ...       ...          ...   \n",
       "215143         0     S7091  3.034338  1.322504  1.259085     0.921761   \n",
       "215144         0     S7070  3.577321  1.532722  1.586918     0.927472   \n",
       "215145         0     S7070  3.239876  1.475545  1.438272     0.936087   \n",
       "215146         0     S7068  3.478297  1.473189  1.478744     0.765125   \n",
       "215147         0     S7101  2.974162  1.366324  1.253978     0.882371   \n",
       "\n",
       "        Mot_CC_Theta  Mot_CC_Sigma  Som_Disp  Som_CC_Theta  ...  Som_CC_Delta  \\\n",
       "25698       0.774044      0.804200  2.317283      0.981321  ...      0.987070   \n",
       "25699       0.808924      0.813156  3.331261      0.930799  ...      0.806586   \n",
       "25700       0.731160      0.698019  3.413144      0.963050  ...      0.386298   \n",
       "25701       0.779113      0.745105  3.362523      0.951927  ...      0.680604   \n",
       "25702       0.945476      0.872156  3.011952      0.941902  ...      0.938718   \n",
       "...              ...           ...       ...           ...  ...           ...   \n",
       "215143      0.966436      0.971496  2.797163      0.970359  ...      0.541272   \n",
       "215144      0.927472      0.927972  3.151484      0.936685  ...      0.458749   \n",
       "215145      0.936087      0.929083  2.980007      0.921387  ...      0.716545   \n",
       "215146      0.828053      0.734246  3.415379      0.923742  ...      0.769699   \n",
       "215147      0.961603      0.961603  3.229786      0.931169  ...      0.686241   \n",
       "\n",
       "        Vis_CC_Gamma  Mot_Gamma  Mot_CC_Gamma  Vis_CC_Beta  Vis_Hurst  \\\n",
       "25698       0.932837   1.590701      0.850342     0.967545   0.956093   \n",
       "25699       0.927611   1.904163      0.856906     0.938395   0.789157   \n",
       "25700       0.934130   2.190386      0.850113     0.939114   0.651875   \n",
       "25701       0.919053   1.671060      0.847344     0.916748   0.704243   \n",
       "25702       0.915246   1.750019      0.896415     0.932768   0.928782   \n",
       "...              ...        ...           ...          ...        ...   \n",
       "215143      0.841883   0.416426      0.860202     0.911593   0.651487   \n",
       "215144      0.698082   1.073763      0.906288     0.829179   0.822102   \n",
       "215145      0.729942   0.815211      0.918187     0.838981   0.755101   \n",
       "215146      0.910860   1.789152      0.750488     0.890407   0.426038   \n",
       "215147      0.479150   0.437639      0.870515     0.599465   0.612220   \n",
       "\n",
       "        Vis_CC_Sigma  Mot_Beta  Som_CC_Gamma  Som_Hurst  \n",
       "25698       0.985163  3.047907      0.947320   0.960286  \n",
       "25699       0.923116  3.157070      0.941685   0.773338  \n",
       "25700       0.945212  3.018505      0.946289   0.689770  \n",
       "25701       0.904325  2.737714      0.937278   0.707645  \n",
       "25702       0.908092  2.212783      0.933922   0.852319  \n",
       "...              ...       ...           ...        ...  \n",
       "215143      0.971595  2.572972      0.901995   0.667459  \n",
       "215144      0.826608  2.479426      0.927068   0.754607  \n",
       "215145      0.866693  2.067910      0.921572   0.745627  \n",
       "215146      0.868962  8.968698      0.926244   0.647426  \n",
       "215147      0.631981  2.091459      0.520276   0.582032  \n",
       "\n",
       "[107574 rows x 30 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_res.loc[X_train_res['Genotype'] == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "550b5fbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Genotype</th>\n",
       "      <th>Animal_ID</th>\n",
       "      <th>Mot_Disp</th>\n",
       "      <th>Vis_HFD</th>\n",
       "      <th>Mot_HFD</th>\n",
       "      <th>Mot_CC_Beta</th>\n",
       "      <th>Mot_CC_Theta</th>\n",
       "      <th>Mot_CC_Sigma</th>\n",
       "      <th>Som_Disp</th>\n",
       "      <th>Som_CC_Theta</th>\n",
       "      <th>...</th>\n",
       "      <th>Som_CC_Delta</th>\n",
       "      <th>Vis_CC_Gamma</th>\n",
       "      <th>Mot_Gamma</th>\n",
       "      <th>Mot_CC_Gamma</th>\n",
       "      <th>Vis_CC_Beta</th>\n",
       "      <th>Vis_Hurst</th>\n",
       "      <th>Vis_CC_Sigma</th>\n",
       "      <th>Mot_Beta</th>\n",
       "      <th>Som_CC_Gamma</th>\n",
       "      <th>Som_Hurst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>S7088</td>\n",
       "      <td>2.924756</td>\n",
       "      <td>1.323589</td>\n",
       "      <td>1.246898</td>\n",
       "      <td>0.930179</td>\n",
       "      <td>0.961686</td>\n",
       "      <td>0.946573</td>\n",
       "      <td>2.837509</td>\n",
       "      <td>0.922718</td>\n",
       "      <td>...</td>\n",
       "      <td>0.689940</td>\n",
       "      <td>0.911559</td>\n",
       "      <td>1.460645</td>\n",
       "      <td>0.936827</td>\n",
       "      <td>0.927070</td>\n",
       "      <td>0.623940</td>\n",
       "      <td>0.962157</td>\n",
       "      <td>3.948171</td>\n",
       "      <td>0.833637</td>\n",
       "      <td>0.570216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>S7088</td>\n",
       "      <td>2.973027</td>\n",
       "      <td>1.325623</td>\n",
       "      <td>1.279200</td>\n",
       "      <td>0.935839</td>\n",
       "      <td>0.976451</td>\n",
       "      <td>0.952313</td>\n",
       "      <td>2.756513</td>\n",
       "      <td>0.876888</td>\n",
       "      <td>...</td>\n",
       "      <td>0.661189</td>\n",
       "      <td>0.887943</td>\n",
       "      <td>0.995496</td>\n",
       "      <td>0.924562</td>\n",
       "      <td>0.899035</td>\n",
       "      <td>0.520271</td>\n",
       "      <td>0.949275</td>\n",
       "      <td>3.280597</td>\n",
       "      <td>0.794466</td>\n",
       "      <td>0.586975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>S7088</td>\n",
       "      <td>3.289658</td>\n",
       "      <td>1.421036</td>\n",
       "      <td>1.401297</td>\n",
       "      <td>0.928618</td>\n",
       "      <td>0.922913</td>\n",
       "      <td>0.944320</td>\n",
       "      <td>3.132441</td>\n",
       "      <td>0.868182</td>\n",
       "      <td>...</td>\n",
       "      <td>0.589786</td>\n",
       "      <td>0.885711</td>\n",
       "      <td>0.635207</td>\n",
       "      <td>0.906288</td>\n",
       "      <td>0.918409</td>\n",
       "      <td>0.675138</td>\n",
       "      <td>0.960132</td>\n",
       "      <td>1.984988</td>\n",
       "      <td>0.792003</td>\n",
       "      <td>0.580442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>S7088</td>\n",
       "      <td>3.030962</td>\n",
       "      <td>1.429642</td>\n",
       "      <td>1.373708</td>\n",
       "      <td>0.948800</td>\n",
       "      <td>0.948598</td>\n",
       "      <td>0.950619</td>\n",
       "      <td>2.872915</td>\n",
       "      <td>0.883786</td>\n",
       "      <td>...</td>\n",
       "      <td>0.535508</td>\n",
       "      <td>0.857754</td>\n",
       "      <td>0.772456</td>\n",
       "      <td>0.906024</td>\n",
       "      <td>0.914521</td>\n",
       "      <td>0.736786</td>\n",
       "      <td>0.941377</td>\n",
       "      <td>2.171369</td>\n",
       "      <td>0.801731</td>\n",
       "      <td>0.659139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>S7088</td>\n",
       "      <td>2.743521</td>\n",
       "      <td>1.305473</td>\n",
       "      <td>1.276098</td>\n",
       "      <td>0.937634</td>\n",
       "      <td>0.963432</td>\n",
       "      <td>0.961127</td>\n",
       "      <td>2.643570</td>\n",
       "      <td>0.916648</td>\n",
       "      <td>...</td>\n",
       "      <td>0.744538</td>\n",
       "      <td>0.831554</td>\n",
       "      <td>0.883347</td>\n",
       "      <td>0.930751</td>\n",
       "      <td>0.913697</td>\n",
       "      <td>0.590836</td>\n",
       "      <td>0.960047</td>\n",
       "      <td>2.313776</td>\n",
       "      <td>0.757164</td>\n",
       "      <td>0.585173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202893</th>\n",
       "      <td>1</td>\n",
       "      <td>S7072</td>\n",
       "      <td>2.458509</td>\n",
       "      <td>1.312435</td>\n",
       "      <td>1.273711</td>\n",
       "      <td>0.929378</td>\n",
       "      <td>0.929378</td>\n",
       "      <td>0.932479</td>\n",
       "      <td>2.458602</td>\n",
       "      <td>0.945120</td>\n",
       "      <td>...</td>\n",
       "      <td>0.960514</td>\n",
       "      <td>0.898890</td>\n",
       "      <td>1.003541</td>\n",
       "      <td>0.883476</td>\n",
       "      <td>0.908942</td>\n",
       "      <td>0.645610</td>\n",
       "      <td>0.915459</td>\n",
       "      <td>5.417707</td>\n",
       "      <td>0.932031</td>\n",
       "      <td>0.606745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202894</th>\n",
       "      <td>1</td>\n",
       "      <td>S7072</td>\n",
       "      <td>2.592141</td>\n",
       "      <td>1.255394</td>\n",
       "      <td>1.209603</td>\n",
       "      <td>0.930623</td>\n",
       "      <td>0.930623</td>\n",
       "      <td>0.955067</td>\n",
       "      <td>2.607698</td>\n",
       "      <td>0.916951</td>\n",
       "      <td>...</td>\n",
       "      <td>0.930429</td>\n",
       "      <td>0.873257</td>\n",
       "      <td>0.999439</td>\n",
       "      <td>0.866240</td>\n",
       "      <td>0.906746</td>\n",
       "      <td>0.616139</td>\n",
       "      <td>0.954223</td>\n",
       "      <td>6.515984</td>\n",
       "      <td>0.905488</td>\n",
       "      <td>0.558705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202895</th>\n",
       "      <td>1</td>\n",
       "      <td>S7072</td>\n",
       "      <td>2.404642</td>\n",
       "      <td>1.225206</td>\n",
       "      <td>1.182093</td>\n",
       "      <td>0.928978</td>\n",
       "      <td>0.928978</td>\n",
       "      <td>0.965543</td>\n",
       "      <td>2.429473</td>\n",
       "      <td>0.940373</td>\n",
       "      <td>...</td>\n",
       "      <td>0.948172</td>\n",
       "      <td>0.854170</td>\n",
       "      <td>0.506982</td>\n",
       "      <td>0.862774</td>\n",
       "      <td>0.907811</td>\n",
       "      <td>0.521719</td>\n",
       "      <td>0.928913</td>\n",
       "      <td>1.679791</td>\n",
       "      <td>0.898441</td>\n",
       "      <td>0.513064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202896</th>\n",
       "      <td>1</td>\n",
       "      <td>S7072</td>\n",
       "      <td>2.378175</td>\n",
       "      <td>1.224009</td>\n",
       "      <td>1.204421</td>\n",
       "      <td>0.919621</td>\n",
       "      <td>0.919621</td>\n",
       "      <td>0.954294</td>\n",
       "      <td>2.347655</td>\n",
       "      <td>0.885987</td>\n",
       "      <td>...</td>\n",
       "      <td>0.936705</td>\n",
       "      <td>0.894853</td>\n",
       "      <td>0.553650</td>\n",
       "      <td>0.841493</td>\n",
       "      <td>0.912082</td>\n",
       "      <td>0.527857</td>\n",
       "      <td>0.926586</td>\n",
       "      <td>2.390964</td>\n",
       "      <td>0.916658</td>\n",
       "      <td>0.419562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202897</th>\n",
       "      <td>1</td>\n",
       "      <td>S7072</td>\n",
       "      <td>2.551280</td>\n",
       "      <td>1.378412</td>\n",
       "      <td>1.316664</td>\n",
       "      <td>0.890414</td>\n",
       "      <td>0.890414</td>\n",
       "      <td>0.926296</td>\n",
       "      <td>2.548916</td>\n",
       "      <td>0.925271</td>\n",
       "      <td>...</td>\n",
       "      <td>0.956267</td>\n",
       "      <td>0.883761</td>\n",
       "      <td>0.781991</td>\n",
       "      <td>0.851226</td>\n",
       "      <td>0.921210</td>\n",
       "      <td>0.692930</td>\n",
       "      <td>0.906114</td>\n",
       "      <td>2.466567</td>\n",
       "      <td>0.916004</td>\n",
       "      <td>0.565751</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>107574 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Genotype Animal_ID  Mot_Disp   Vis_HFD   Mot_HFD  Mot_CC_Beta  \\\n",
       "0              1     S7088  2.924756  1.323589  1.246898     0.930179   \n",
       "1              1     S7088  2.973027  1.325623  1.279200     0.935839   \n",
       "2              1     S7088  3.289658  1.421036  1.401297     0.928618   \n",
       "3              1     S7088  3.030962  1.429642  1.373708     0.948800   \n",
       "4              1     S7088  2.743521  1.305473  1.276098     0.937634   \n",
       "...          ...       ...       ...       ...       ...          ...   \n",
       "202893         1     S7072  2.458509  1.312435  1.273711     0.929378   \n",
       "202894         1     S7072  2.592141  1.255394  1.209603     0.930623   \n",
       "202895         1     S7072  2.404642  1.225206  1.182093     0.928978   \n",
       "202896         1     S7072  2.378175  1.224009  1.204421     0.919621   \n",
       "202897         1     S7072  2.551280  1.378412  1.316664     0.890414   \n",
       "\n",
       "        Mot_CC_Theta  Mot_CC_Sigma  Som_Disp  Som_CC_Theta  ...  Som_CC_Delta  \\\n",
       "0           0.961686      0.946573  2.837509      0.922718  ...      0.689940   \n",
       "1           0.976451      0.952313  2.756513      0.876888  ...      0.661189   \n",
       "2           0.922913      0.944320  3.132441      0.868182  ...      0.589786   \n",
       "3           0.948598      0.950619  2.872915      0.883786  ...      0.535508   \n",
       "4           0.963432      0.961127  2.643570      0.916648  ...      0.744538   \n",
       "...              ...           ...       ...           ...  ...           ...   \n",
       "202893      0.929378      0.932479  2.458602      0.945120  ...      0.960514   \n",
       "202894      0.930623      0.955067  2.607698      0.916951  ...      0.930429   \n",
       "202895      0.928978      0.965543  2.429473      0.940373  ...      0.948172   \n",
       "202896      0.919621      0.954294  2.347655      0.885987  ...      0.936705   \n",
       "202897      0.890414      0.926296  2.548916      0.925271  ...      0.956267   \n",
       "\n",
       "        Vis_CC_Gamma  Mot_Gamma  Mot_CC_Gamma  Vis_CC_Beta  Vis_Hurst  \\\n",
       "0           0.911559   1.460645      0.936827     0.927070   0.623940   \n",
       "1           0.887943   0.995496      0.924562     0.899035   0.520271   \n",
       "2           0.885711   0.635207      0.906288     0.918409   0.675138   \n",
       "3           0.857754   0.772456      0.906024     0.914521   0.736786   \n",
       "4           0.831554   0.883347      0.930751     0.913697   0.590836   \n",
       "...              ...        ...           ...          ...        ...   \n",
       "202893      0.898890   1.003541      0.883476     0.908942   0.645610   \n",
       "202894      0.873257   0.999439      0.866240     0.906746   0.616139   \n",
       "202895      0.854170   0.506982      0.862774     0.907811   0.521719   \n",
       "202896      0.894853   0.553650      0.841493     0.912082   0.527857   \n",
       "202897      0.883761   0.781991      0.851226     0.921210   0.692930   \n",
       "\n",
       "        Vis_CC_Sigma  Mot_Beta  Som_CC_Gamma  Som_Hurst  \n",
       "0           0.962157  3.948171      0.833637   0.570216  \n",
       "1           0.949275  3.280597      0.794466   0.586975  \n",
       "2           0.960132  1.984988      0.792003   0.580442  \n",
       "3           0.941377  2.171369      0.801731   0.659139  \n",
       "4           0.960047  2.313776      0.757164   0.585173  \n",
       "...              ...       ...           ...        ...  \n",
       "202893      0.915459  5.417707      0.932031   0.606745  \n",
       "202894      0.954223  6.515984      0.905488   0.558705  \n",
       "202895      0.928913  1.679791      0.898441   0.513064  \n",
       "202896      0.926586  2.390964      0.916658   0.419562  \n",
       "202897      0.906114  2.466567      0.916004   0.565751  \n",
       "\n",
       "[107574 rows x 30 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_res.loc[X_train_res['Genotype'] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bc34d163",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_new = X_train_res.iloc[:, 2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3b6f8a97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['S7088', 'S7088', 'S7088', ..., 'S7070', 'S7068', 'S7101'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "group_by_patient_id = X_train_res.groupby(['Animal_ID'])\n",
    "groups_by_patient_id_list = np.array(X_train_res['Animal_ID'].values)\n",
    "groups_by_patient_id_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "335def2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "n_splits = 3\n",
    "group_kfold = GroupKFold(n_splits = n_splits)\n",
    "print(group_kfold.get_n_splits(X_train_new, y_train_res, groups = groups_by_patient_id_list))\n",
    "\n",
    "result = []\n",
    "y_result = []\n",
    "for train_idx, val_idx in group_kfold.split(X_train_new, y_train_res, groups = groups_by_patient_id_list):\n",
    "    train_fold = X_train_new.iloc[train_idx]\n",
    "    val_fold = X_train_new.iloc[val_idx]\n",
    "    train_y_fold = y_train_res.iloc[train_idx]\n",
    "    val_y_fold = y_train_res.iloc[val_idx]\n",
    "    result.append((train_fold, val_fold))\n",
    "    y_result.append((train_y_fold, val_y_fold))\n",
    "    \n",
    "train_fold_1, val_fold_1 = result[0][0],result[0][1]\n",
    "train_fold_2, val_fold_2 = result[1][0],result[1][1]\n",
    "train_fold_3, val_fold_3 = result[2][0],result[2][1]\n",
    "\n",
    "\n",
    "y_train_fold_1, y_val_fold_1 = y_result[0][0],y_result[0][1]\n",
    "y_train_fold_2, y_val_fold_2 = y_result[1][0],y_result[1][1]\n",
    "y_train_fold_3, y_val_fold_3 = y_result[2][0],y_result[2][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5105700e",
   "metadata": {},
   "outputs": [],
   "source": [
    "options = {'max_depth': hp.quniform('max_depth', 1, 8, 1), #tree\n",
    "            'min_child_weight': hp.loguniform('min_child_weight', -2, 3),\n",
    "            'subsample': hp.uniform('subsample', 0.5, 1), #stochastic\n",
    "            'colsample_bytree': hp.uniform('colsample_bytree', 0.5, 1),\n",
    "            'reg_alpha': hp.uniform('reg_alpha', 0, 10), \n",
    "            'reg_lambda': hp.uniform('reg_lambda', 1, 10),\n",
    "            'gamma': hp.loguniform('gamma', -10, 10),\n",
    "            'learning_rate': hp.loguniform('learning_rate', -7, 0), \n",
    "            'random_state': 2\n",
    "          }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9473d2cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hyperparameter_tuning(space: Dict[str, Union[float, int]],\n",
    "                         X_train: pd.DataFrame, y_train: pd.Series, \n",
    "                         X_test: pd.DataFrame, y_test: pd.Series, \n",
    "                         early_stopping_rounds: int = 50, \n",
    "                         metric: callable = roc_auc_score) -> Dict[str, Any]:\n",
    "    \n",
    "    '''Perform hyperparameter runing for an XGBoost classifier. \n",
    "    \n",
    "    This function takes a dictionary of hyperparameters, training and test data, and an optional value\n",
    "    for early stopping rounds, and returns a dictionary with the loss and model resulting from \n",
    "    the tuning process. The model is trained using the training data and evaluated on the test \n",
    "    data. The loss is computed as the negative of the accuracy score.\n",
    "    \n",
    "    space: Dict[str, Union[float, int]]\n",
    "    A dictionary of hyperparameters for the XGBoost classifier\n",
    "    \n",
    "    X_train: pd.DataFrame\n",
    "    The training data\n",
    "    \n",
    "    y_train: pd.Series\n",
    "    The training target\n",
    "    \n",
    "    X_test: pd.Dataframe\n",
    "    The test data\n",
    "    \n",
    "    y_test: pd.Series\n",
    "    The test target\n",
    "    \n",
    "    early_stopping rounds: int, optional \n",
    "    The number of early stopping rounds to use. The deault is 50\n",
    "    \n",
    "    metric: callable\n",
    "    Metric to maximise. Default is accuracy\n",
    "    \n",
    "    Returns: \n",
    "    Dict[str, Any]\n",
    "        A dictionary with the loss and model resulting from the tuning process. \n",
    "        The loss is a float, and the model is an XGBoost classifier'''\n",
    "    \n",
    "    int_vals = ['max_depth', 'reg_alpha']\n",
    "    \n",
    "    space = {k: (int(val) if k in int_vals else val)\n",
    "            for k, val in space.items()}\n",
    "    \n",
    "    space['early_stopping_rounds'] = early_stopping_rounds\n",
    "    \n",
    "    model = xgb.XGBClassifier(**space)\n",
    "    evaluation = [(X_train, y_train), \n",
    "                 (X_test, y_test)]\n",
    "    model.fit(X_train, y_train, eval_set = evaluation, verbose = False)\n",
    "    \n",
    "    score = metrics.roc_auc_score(y_test, model.predict(X_test))\n",
    "    return {'loss': -score, 'status': STATUS_OK, 'model': model}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "194501d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████| 100/100 [03:26<00:00,  2.06s/trial, best loss: -0.7424872733955504]\n"
     ]
    }
   ],
   "source": [
    "trials = Trials()\n",
    "best_1 = fmin(fn = lambda space: hyperparameter_tuning(space, X_train = train_fold_1, y_train = y_train_fold_1,\n",
    "                                                     X_test = val_fold_1, y_test = y_val_fold_1),\n",
    "            space = options,\n",
    "            algo = tpe.suggest,\n",
    "            max_evals = 100,\n",
    "            trials = trials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1f4838d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'colsample_bytree': 0.6636760214761867,\n",
       " 'gamma': 0.006513284821458478,\n",
       " 'learning_rate': 0.3736188068300677,\n",
       " 'max_depth': 1.0,\n",
       " 'min_child_weight': 0.30117912165572236,\n",
       " 'reg_alpha': 5.655686765890902,\n",
       " 'reg_lambda': 7.458756456257207,\n",
       " 'subsample': 0.8219900876873194}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a91d49e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████| 100/100 [04:28<00:00,  2.68s/trial, best loss: -0.7265829693967553]\n"
     ]
    }
   ],
   "source": [
    "trials = Trials()\n",
    "best_2 = fmin(fn = lambda space: hyperparameter_tuning(space, X_train = train_fold_2, y_train = y_train_fold_2,\n",
    "                                                     X_test = val_fold_2, y_test = y_val_fold_2),\n",
    "            space = options,\n",
    "            algo = tpe.suggest,\n",
    "            max_evals = 100,\n",
    "            trials = trials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "bd09767f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'colsample_bytree': 0.8015650075876946,\n",
       " 'gamma': 183.60316497522538,\n",
       " 'learning_rate': 0.7907002938986372,\n",
       " 'max_depth': 1.0,\n",
       " 'min_child_weight': 1.887561168339608,\n",
       " 'reg_alpha': 8.535450510492824,\n",
       " 'reg_lambda': 8.093523019340271,\n",
       " 'subsample': 0.713040484566234}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b3a77e8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 31%|██▏    | 31/100 [01:39<03:40,  3.20s/trial, best loss: -0.6385687931046445]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[42], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m trials \u001b[38;5;241m=\u001b[39m Trials()\n\u001b[0;32m----> 2\u001b[0m best_3 \u001b[38;5;241m=\u001b[39m \u001b[43mfmin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mspace\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mhyperparameter_tuning\u001b[49m\u001b[43m(\u001b[49m\u001b[43mspace\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtrain_fold_3\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43my_train_fold_3\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m                                                     \u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mval_fold_3\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43my_val_fold_3\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m            \u001b[49m\u001b[43mspace\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m            \u001b[49m\u001b[43malgo\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtpe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msuggest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmax_evals\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtrials\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtrials\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/hyperopt/fmin.py:540\u001b[0m, in \u001b[0;36mfmin\u001b[0;34m(fn, space, algo, max_evals, timeout, loss_threshold, trials, rstate, allow_trials_fmin, pass_expr_memo_ctrl, catch_eval_exceptions, verbose, return_argmin, points_to_evaluate, max_queue_len, show_progressbar, early_stop_fn, trials_save_file)\u001b[0m\n\u001b[1;32m    537\u001b[0m     fn \u001b[38;5;241m=\u001b[39m __objective_fmin_wrapper(fn)\n\u001b[1;32m    539\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m allow_trials_fmin \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(trials, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfmin\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 540\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtrials\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfmin\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    541\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    542\u001b[0m \u001b[43m        \u001b[49m\u001b[43mspace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    543\u001b[0m \u001b[43m        \u001b[49m\u001b[43malgo\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43malgo\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    544\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_evals\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_evals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    545\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    546\u001b[0m \u001b[43m        \u001b[49m\u001b[43mloss_threshold\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mloss_threshold\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    547\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_queue_len\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_queue_len\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    548\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrstate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrstate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    549\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpass_expr_memo_ctrl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpass_expr_memo_ctrl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    550\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    551\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcatch_eval_exceptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcatch_eval_exceptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    552\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_argmin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_argmin\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    553\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshow_progressbar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshow_progressbar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    554\u001b[0m \u001b[43m        \u001b[49m\u001b[43mearly_stop_fn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mearly_stop_fn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    555\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrials_save_file\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrials_save_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    556\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    558\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m trials \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    559\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(trials_save_file):\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/hyperopt/base.py:671\u001b[0m, in \u001b[0;36mTrials.fmin\u001b[0;34m(self, fn, space, algo, max_evals, timeout, loss_threshold, max_queue_len, rstate, verbose, pass_expr_memo_ctrl, catch_eval_exceptions, return_argmin, show_progressbar, early_stop_fn, trials_save_file)\u001b[0m\n\u001b[1;32m    666\u001b[0m \u001b[38;5;66;03m# -- Stop-gap implementation!\u001b[39;00m\n\u001b[1;32m    667\u001b[0m \u001b[38;5;66;03m#    fmin should have been a Trials method in the first place\u001b[39;00m\n\u001b[1;32m    668\u001b[0m \u001b[38;5;66;03m#    but for now it's still sitting in another file.\u001b[39;00m\n\u001b[1;32m    669\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfmin\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m fmin\n\u001b[0;32m--> 671\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfmin\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    672\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    673\u001b[0m \u001b[43m    \u001b[49m\u001b[43mspace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    674\u001b[0m \u001b[43m    \u001b[49m\u001b[43malgo\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43malgo\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    675\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_evals\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_evals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    676\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    677\u001b[0m \u001b[43m    \u001b[49m\u001b[43mloss_threshold\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mloss_threshold\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    678\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    679\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrstate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrstate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    680\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    681\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_queue_len\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_queue_len\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    682\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_trials_fmin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# -- prevent recursion\u001b[39;49;00m\n\u001b[1;32m    683\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpass_expr_memo_ctrl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpass_expr_memo_ctrl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    684\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcatch_eval_exceptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcatch_eval_exceptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    685\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_argmin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_argmin\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    686\u001b[0m \u001b[43m    \u001b[49m\u001b[43mshow_progressbar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshow_progressbar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    687\u001b[0m \u001b[43m    \u001b[49m\u001b[43mearly_stop_fn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mearly_stop_fn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    688\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrials_save_file\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrials_save_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    689\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/hyperopt/fmin.py:586\u001b[0m, in \u001b[0;36mfmin\u001b[0;34m(fn, space, algo, max_evals, timeout, loss_threshold, trials, rstate, allow_trials_fmin, pass_expr_memo_ctrl, catch_eval_exceptions, verbose, return_argmin, points_to_evaluate, max_queue_len, show_progressbar, early_stop_fn, trials_save_file)\u001b[0m\n\u001b[1;32m    583\u001b[0m rval\u001b[38;5;241m.\u001b[39mcatch_eval_exceptions \u001b[38;5;241m=\u001b[39m catch_eval_exceptions\n\u001b[1;32m    585\u001b[0m \u001b[38;5;66;03m# next line is where the fmin is actually executed\u001b[39;00m\n\u001b[0;32m--> 586\u001b[0m \u001b[43mrval\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexhaust\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    588\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m return_argmin:\n\u001b[1;32m    589\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(trials\u001b[38;5;241m.\u001b[39mtrials) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/hyperopt/fmin.py:364\u001b[0m, in \u001b[0;36mFMinIter.exhaust\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    362\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mexhaust\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    363\u001b[0m     n_done \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrials)\n\u001b[0;32m--> 364\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_evals\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mn_done\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mblock_until_done\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43masynchronous\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    365\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrials\u001b[38;5;241m.\u001b[39mrefresh()\n\u001b[1;32m    366\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/hyperopt/fmin.py:300\u001b[0m, in \u001b[0;36mFMinIter.run\u001b[0;34m(self, N, block_until_done)\u001b[0m\n\u001b[1;32m    297\u001b[0m     time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpoll_interval_secs)\n\u001b[1;32m    298\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    299\u001b[0m     \u001b[38;5;66;03m# -- loop over trials and do the jobs directly\u001b[39;00m\n\u001b[0;32m--> 300\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mserial_evaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    302\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrials\u001b[38;5;241m.\u001b[39mrefresh()\n\u001b[1;32m    303\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrials_save_file \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/hyperopt/fmin.py:178\u001b[0m, in \u001b[0;36mFMinIter.serial_evaluate\u001b[0;34m(self, N)\u001b[0m\n\u001b[1;32m    176\u001b[0m ctrl \u001b[38;5;241m=\u001b[39m base\u001b[38;5;241m.\u001b[39mCtrl(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrials, current_trial\u001b[38;5;241m=\u001b[39mtrial)\n\u001b[1;32m    177\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 178\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdomain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mspec\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctrl\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    179\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    180\u001b[0m     logger\u001b[38;5;241m.\u001b[39merror(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mjob exception: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mstr\u001b[39m(e))\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/hyperopt/base.py:892\u001b[0m, in \u001b[0;36mDomain.evaluate\u001b[0;34m(self, config, ctrl, attach_attachments)\u001b[0m\n\u001b[1;32m    883\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    884\u001b[0m     \u001b[38;5;66;03m# -- the \"work\" of evaluating `config` can be written\u001b[39;00m\n\u001b[1;32m    885\u001b[0m     \u001b[38;5;66;03m#    either into the pyll part (self.expr)\u001b[39;00m\n\u001b[1;32m    886\u001b[0m     \u001b[38;5;66;03m#    or the normal Python part (self.fn)\u001b[39;00m\n\u001b[1;32m    887\u001b[0m     pyll_rval \u001b[38;5;241m=\u001b[39m pyll\u001b[38;5;241m.\u001b[39mrec_eval(\n\u001b[1;32m    888\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexpr,\n\u001b[1;32m    889\u001b[0m         memo\u001b[38;5;241m=\u001b[39mmemo,\n\u001b[1;32m    890\u001b[0m         print_node_on_error\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrec_eval_print_node_on_error,\n\u001b[1;32m    891\u001b[0m     )\n\u001b[0;32m--> 892\u001b[0m     rval \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpyll_rval\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    894\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(rval, (\u001b[38;5;28mfloat\u001b[39m, \u001b[38;5;28mint\u001b[39m, np\u001b[38;5;241m.\u001b[39mnumber)):\n\u001b[1;32m    895\u001b[0m     dict_rval \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mfloat\u001b[39m(rval), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstatus\u001b[39m\u001b[38;5;124m\"\u001b[39m: STATUS_OK}\n",
      "Cell \u001b[0;32mIn[42], line 2\u001b[0m, in \u001b[0;36m<lambda>\u001b[0;34m(space)\u001b[0m\n\u001b[1;32m      1\u001b[0m trials \u001b[38;5;241m=\u001b[39m Trials()\n\u001b[0;32m----> 2\u001b[0m best_3 \u001b[38;5;241m=\u001b[39m fmin(fn \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m space: \u001b[43mhyperparameter_tuning\u001b[49m\u001b[43m(\u001b[49m\u001b[43mspace\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtrain_fold_3\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43my_train_fold_3\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m                                                     \u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mval_fold_3\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43my_val_fold_3\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m      4\u001b[0m             space \u001b[38;5;241m=\u001b[39m options,\n\u001b[1;32m      5\u001b[0m             algo \u001b[38;5;241m=\u001b[39m tpe\u001b[38;5;241m.\u001b[39msuggest,\n\u001b[1;32m      6\u001b[0m             max_evals \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m100\u001b[39m,\n\u001b[1;32m      7\u001b[0m             trials \u001b[38;5;241m=\u001b[39m trials)\n",
      "Cell \u001b[0;32mIn[30], line 50\u001b[0m, in \u001b[0;36mhyperparameter_tuning\u001b[0;34m(space, X_train, y_train, X_test, y_test, early_stopping_rounds, metric)\u001b[0m\n\u001b[1;32m     47\u001b[0m model \u001b[38;5;241m=\u001b[39m xgb\u001b[38;5;241m.\u001b[39mXGBClassifier(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mspace)\n\u001b[1;32m     48\u001b[0m evaluation \u001b[38;5;241m=\u001b[39m [(X_train, y_train), \n\u001b[1;32m     49\u001b[0m              (X_test, y_test)]\n\u001b[0;32m---> 50\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meval_set\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mevaluation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     52\u001b[0m score \u001b[38;5;241m=\u001b[39m metrics\u001b[38;5;241m.\u001b[39mroc_auc_score(y_test, model\u001b[38;5;241m.\u001b[39mpredict(X_test))\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m-\u001b[39mscore, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstatus\u001b[39m\u001b[38;5;124m'\u001b[39m: STATUS_OK, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m'\u001b[39m: model}\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/xgboost/core.py:620\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig\u001b[38;5;241m.\u001b[39mparameters, args):\n\u001b[1;32m    619\u001b[0m     kwargs[k] \u001b[38;5;241m=\u001b[39m arg\n\u001b[0;32m--> 620\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/xgboost/sklearn.py:1490\u001b[0m, in \u001b[0;36mXGBClassifier.fit\u001b[0;34m(self, X, y, sample_weight, base_margin, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model, sample_weight_eval_set, base_margin_eval_set, feature_weights, callbacks)\u001b[0m\n\u001b[1;32m   1462\u001b[0m (\n\u001b[1;32m   1463\u001b[0m     model,\n\u001b[1;32m   1464\u001b[0m     metric,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1469\u001b[0m     xgb_model, eval_metric, params, early_stopping_rounds, callbacks\n\u001b[1;32m   1470\u001b[0m )\n\u001b[1;32m   1471\u001b[0m train_dmatrix, evals \u001b[38;5;241m=\u001b[39m _wrap_evaluation_matrices(\n\u001b[1;32m   1472\u001b[0m     missing\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmissing,\n\u001b[1;32m   1473\u001b[0m     X\u001b[38;5;241m=\u001b[39mX,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1487\u001b[0m     feature_types\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeature_types,\n\u001b[1;32m   1488\u001b[0m )\n\u001b[0;32m-> 1490\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_Booster \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1491\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1492\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_dmatrix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1493\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_num_boosting_rounds\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1494\u001b[0m \u001b[43m    \u001b[49m\u001b[43mevals\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mevals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1495\u001b[0m \u001b[43m    \u001b[49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1496\u001b[0m \u001b[43m    \u001b[49m\u001b[43mevals_result\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mevals_result\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1497\u001b[0m \u001b[43m    \u001b[49m\u001b[43mobj\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1498\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcustom_metric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetric\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1499\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1500\u001b[0m \u001b[43m    \u001b[49m\u001b[43mxgb_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1501\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1504\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobjective):\n\u001b[1;32m   1505\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobjective \u001b[38;5;241m=\u001b[39m params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mobjective\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/xgboost/core.py:620\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig\u001b[38;5;241m.\u001b[39mparameters, args):\n\u001b[1;32m    619\u001b[0m     kwargs[k] \u001b[38;5;241m=\u001b[39m arg\n\u001b[0;32m--> 620\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/xgboost/training.py:185\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, custom_metric)\u001b[0m\n\u001b[1;32m    183\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cb_container\u001b[38;5;241m.\u001b[39mbefore_iteration(bst, i, dtrain, evals):\n\u001b[1;32m    184\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m--> 185\u001b[0m \u001b[43mbst\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    186\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cb_container\u001b[38;5;241m.\u001b[39mafter_iteration(bst, i, dtrain, evals):\n\u001b[1;32m    187\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/xgboost/core.py:1918\u001b[0m, in \u001b[0;36mBooster.update\u001b[0;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[1;32m   1915\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_dmatrix_features(dtrain)\n\u001b[1;32m   1917\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m fobj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1918\u001b[0m     _check_call(\u001b[43m_LIB\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mXGBoosterUpdateOneIter\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1919\u001b[0m \u001b[43m                                            \u001b[49m\u001b[43mctypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mc_int\u001b[49m\u001b[43m(\u001b[49m\u001b[43miteration\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1920\u001b[0m \u001b[43m                                            \u001b[49m\u001b[43mdtrain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   1921\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1922\u001b[0m     pred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredict(dtrain, output_margin\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, training\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "trials = Trials()\n",
    "best_3 = fmin(fn = lambda space: hyperparameter_tuning(space, X_train = train_fold_3, y_train = y_train_fold_3,\n",
    "                                                     X_test = val_fold_3, y_test = y_val_fold_3),\n",
    "            space = options,\n",
    "            algo = tpe.suggest,\n",
    "            max_evals = 100,\n",
    "            trials = trials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdcfd933",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1852d970",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_previous = {'colsample_bytree': 0.5640125501892845,\n",
    " 'gamma': 886.1540988328427,\n",
    " 'learning_rate': 0.07054345778305847,\n",
    " 'max_depth': 4,\n",
    " 'min_child_weight': 2.637224503774358,\n",
    " 'reg_alpha': 4.604438973488756,\n",
    " 'reg_lambda': 3.1664179220499076,\n",
    " 'subsample': 0.6401529750159931}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "d2559797",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_2 = {'colsample_bytree': 0.5290850327180321,\n",
    " 'gamma': 0.0001460284442936826,\n",
    " 'learning_rate': 0.5814438491118862,\n",
    " 'max_depth': 4,\n",
    " 'min_child_weight': 0.24334861504536942,\n",
    " 'reg_alpha': 5.986997824876159,\n",
    " 'reg_lambda': 1.4665208209606782,\n",
    " 'subsample': 0.6151436158918928}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "id": "e0cbd724",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=0.5640125501892845, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=886.1540988328427, gpu_id=None, grow_policy=None,\n",
       "              importance_type=None, interaction_constraints=None,\n",
       "              learning_rate=0.07054345778305847, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=4, max_leaves=None,\n",
       "              min_child_weight=2.637224503774358, missing=nan,\n",
       "              monotone_constraints=None, n_estimators=100, n_jobs=None,\n",
       "              num_parallel_tree=None, predictor=None, random_state=None, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=0.5640125501892845, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=886.1540988328427, gpu_id=None, grow_policy=None,\n",
       "              importance_type=None, interaction_constraints=None,\n",
       "              learning_rate=0.07054345778305847, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=4, max_leaves=None,\n",
       "              min_child_weight=2.637224503774358, missing=nan,\n",
       "              monotone_constraints=None, n_estimators=100, n_jobs=None,\n",
       "              num_parallel_tree=None, predictor=None, random_state=None, ...)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=0.5640125501892845, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=886.1540988328427, gpu_id=None, grow_policy=None,\n",
       "              importance_type=None, interaction_constraints=None,\n",
       "              learning_rate=0.07054345778305847, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=4, max_leaves=None,\n",
       "              min_child_weight=2.637224503774358, missing=nan,\n",
       "              monotone_constraints=None, n_estimators=100, n_jobs=None,\n",
       "              num_parallel_tree=None, predictor=None, random_state=None, ...)"
      ]
     },
     "execution_count": 261,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model = xgb.XGBClassifier(**best_previous)\n",
    "best_model.fit(X_train_new, y_train_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "id": "bc3d7faa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.06298449612403101"
      ]
     },
     "execution_count": 265,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model.score(X_test_new, y_test_res)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
