{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ebfcfb06",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import xgboost as xgb\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GroupShuffleSplit, GroupKFold, StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "\n",
    "from hyperopt import fmin, tpe, hp, STATUS_OK, Trials\n",
    "from typing import Any, Dict, Union\n",
    "\n",
    "from yellowbrick import model_selection as ms\n",
    "from yellowbrick.model_selection import validation_curve\n",
    "\n",
    "from sklearn import metrics\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "from boruta import BorutaPy\n",
    "from BorutaShap import BorutaShap, load_data\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "129631cf",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'all_train_ids' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 16\u001b[0m\n\u001b[1;32m     14\u001b[0m het_test \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     15\u001b[0m wt_test \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m---> 16\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m tr_id \u001b[38;5;129;01min\u001b[39;00m \u001b[43mall_train_ids\u001b[49m:\n\u001b[1;32m     17\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m tr_id \u001b[38;5;129;01min\u001b[39;00m SYNGAP_het:\n\u001b[1;32m     18\u001b[0m         het_train\u001b[38;5;241m.\u001b[39mappend(tr_id)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'all_train_ids' is not defined"
     ]
    }
   ],
   "source": [
    "patient_list  =  ['P1 N1', 'P2 N1', 'P3 N1', 'P3 N2','P4 N2', 'P5 N1',\n",
    "                   'P6 N2', 'P7 N1','P8 N1','P10 N1', 'P11 N1', 'P15 N1',\n",
    "                  'P16 N1', 'P17 N1', 'P18 N1','P20 N1', 'P21 N1', 'P21 N2', 'P21 N3',\n",
    "                  'P22 N1','P23 N1', 'P23 N3', 'P24 N1','P27 N1','P28 N1',\n",
    "                  'P28 N2', 'P29 N2', 'P30 N1']  #'P6 N1','P23 N2',\n",
    "\n",
    "human_wt = ['P1', 'P11', 'P17', 'P18', 'P21', 'P24', 'P27','P28', 'P29', 'P4']\n",
    "\n",
    "human_gap = ['P3','P10', 'P15', 'P16', 'P2', 'P5', 'P6', 'P7','P8', 'P20',  'P22',\n",
    "            'P23', 'P30'] \n",
    "\n",
    "het_train = []\n",
    "wt_train = []\n",
    "het_test = []\n",
    "wt_test = []\n",
    "for tr_id in all_train_ids:\n",
    "    if tr_id in SYNGAP_het:\n",
    "        het_train.append(tr_id)\n",
    "    if tr_id in SYNGAP_wt:\n",
    "        wt_train.append(tr_id)\n",
    "\n",
    "for tr_id in all_test_ids:\n",
    "    if tr_id in SYNGAP_het:\n",
    "        het_test.append(tr_id)\n",
    "    if tr_id in SYNGAP_wt:\n",
    "        wt_test.append(tr_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "726e1ad7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P1 N1_E1_O1.npy\n",
      "P1 N1_E2_M2.npy\n",
      "P1 N1_C3_O1.npy\n",
      "P1 N1_E1_F3.npy\n",
      "P1 N1_F3_C3.npy\n",
      "P1 N1_E2_O1.npy\n",
      "P1 N1.csv\n",
      "P1 N1_E1_M2.npy\n",
      "P1 N1_C3_M2.npy\n",
      "P1 N1_F3_M2.npy\n",
      "P1 N1_E1_C3.npy\n",
      "P1 N1_E1_E2.npy\n",
      "P1 N1_E2_F3.npy\n",
      "P1 N1_F3_O1.npy\n",
      "P1 N1_O1_M2.npy\n",
      "P1 N1_E2_C3.npy\n"
     ]
    }
   ],
   "source": [
    "for file in os.listdir('/home/melissa/RESULTS/XGBoost/Human_SYNGAP1/Cross_Corr_Channels/'):\n",
    "    if file.startswith('P1 N1'):\n",
    "        print(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bb89530d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_hfd = np.load(hfd_dir + 'P23 N3_01_hfd.npy')\n",
    "#test_hfd.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8296f77c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#patient = 'P23 N3'\n",
    "#hurst_E1 = np.load(hurst_dir + patient + '_E1_hurst.npy')\n",
    "#hurst_E2 =  np.load(hurst_dir + patient + '_E2_hurst.npy')\n",
    "#hurst_F3 =  np.load(hurst_dir + patient + '_F3_hurst.npy')\n",
    "#hurst_C3 =  np.load(hurst_dir + patient + '_C3_hurst.npy')\n",
    "#hurst_O1 = np.load(hurst_dir + patient + '_01_hurst.npy')\n",
    "#hurst_M2 =  np.load(hurst_dir + patient + '_M2_hurst.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "0c34cf3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hurst_E1 = [hurst[0] for hurst in hurst_E1]\n",
    "#hurst_E2 = [hurst[0] for hurst in hurst_E2]\n",
    "#hurst_F3 = [hurst[0] for hurst in hurst_F3]\n",
    "#hurst_C3 = [hurst[0] for hurst in hurst_C3]\n",
    "#hurst_O1 = [hurst[0] for hurst in hurst_O1]\n",
    "#hurst_M2 = [hurst[0] for hurst in hurst_M2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cd19c5d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.save(hurst_dir + patient + '_E1_hurst.npy', hurst_E1)\n",
    "#np.save(hurst_dir + patient + '_E2_hurst.npy', hurst_E2)\n",
    "#np.save(hurst_dir + patient + '_F3_hurst.npy', hurst_F3)\n",
    "#np.save(hurst_dir + patient + '_C3_hurst.npy', hurst_C3)\n",
    "#np.save(hurst_dir + patient + '_01_hurst.npy', hurst_O1)\n",
    "#np.save(hurst_dir + patient + '_M2_hurst.npy', hurst_M2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bb1b485f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P1 N1\n",
      "P2 N1\n",
      "P3 N1\n",
      "P3 N2\n",
      "P4 N2\n",
      "P5 N1\n",
      "P6 N2\n",
      "P7 N1\n",
      "P8 N1\n",
      "P10 N1\n",
      "P11 N1\n",
      "P15 N1\n",
      "P16 N1\n",
      "P17 N1\n",
      "P18 N1\n",
      "P20 N1\n",
      "P21 N1\n",
      "P21 N2\n",
      "P21 N3\n",
      "P22 N1\n",
      "P23 N1\n",
      "P23 N3\n",
      "P24 N1\n",
      "P27 N1\n",
      "P28 N1\n",
      "P28 N2\n",
      "P29 N2\n",
      "P30 N1\n"
     ]
    }
   ],
   "source": [
    "hfd_dir = '/home/melissa/RESULTS/FINAL_MODEL/Human/Complexity/HFD_All_Epochs/'\n",
    "hurst_dir = '/home/melissa/RESULTS/FINAL_MODEL/Human/Complexity/Hurst/'\n",
    "entropy_dir = '/home/melissa/RESULTS/FINAL_MODEL/Human/Complexity/DispEn/'\n",
    "\n",
    "delta_dir = '/home/melissa/RESULTS/XGBoost/Human_SYNGAP1/Delta_Power/'\n",
    "theta_dir = '/home/melissa/RESULTS/XGBoost/Human_SYNGAP1/Theta_Power/'\n",
    "alpha_dir = '/home/melissa/RESULTS/XGBoost/Human_SYNGAP1/Alpha_Power/'\n",
    "beta_dir = '/home/melissa/RESULTS/XGBoost/Human_SYNGAP1/Beta_Power/'\n",
    "\n",
    "cc_dir = '/home/melissa/RESULTS/FINAL_MODEL/Human/Cross_Corr_Channels/'\n",
    "plv_dir = '/home/melissa/RESULTS/XGBoost/Human_SYNGAP1/Phase_Lock_Channels/'\n",
    "\n",
    "all_patients = []\n",
    "\n",
    "for patient in patient_list:\n",
    "        print(patient)\n",
    "        len_data = len(np.load(hfd_dir + patient + '_E1_hfd.npy'))\n",
    "        data_dict = {\n",
    "            'Patient_ID': [patient]*len_data,\n",
    "            'hfd_E1': np.load(hfd_dir + patient + '_E1_hfd.npy'),\n",
    "            'hfd_E2': np.load(hfd_dir + patient + '_E2_hfd.npy'),\n",
    "            'hfd_F3': np.load(hfd_dir + patient + '_F3_hfd.npy'),\n",
    "            'hfd_C3': np.load(hfd_dir + patient + '_C3_hfd.npy'),\n",
    "            'hfd_O1': np.load(hfd_dir + patient + '_01_hfd.npy'),\n",
    "            'hfd_M2': np.load(hfd_dir + patient + '_M2_hfd.npy'),\n",
    "                \n",
    "            'hurst_E1': np.load(hurst_dir + patient + '_E1_hurst.npy'),\n",
    "            'hurst_E2': np.load(hurst_dir + patient + '_E2_hurst.npy'),\n",
    "            'hurst_F3': np.load(hurst_dir + patient + '_F3_hurst.npy'),\n",
    "            'hurst_C3': np.load(hurst_dir + patient + '_C3_hurst.npy'),\n",
    "            'hurst_O1': np.load(hurst_dir + patient + '_01_hurst.npy'),\n",
    "            'hurst_M2': np.load(hurst_dir + patient + '_M2_hurst.npy'),\n",
    "                \n",
    "            'entr_E1': np.load(entropy_dir + patient + '_E1_dispen.npy'),\n",
    "            'entr_E2': np.load(entropy_dir + patient + '_E2_dispen.npy'),\n",
    "            'entr_F3': np.load(entropy_dir + patient + '_F3_dispen.npy'),\n",
    "            'entr_C3': np.load(entropy_dir + patient + '_C3_dispen.npy'),\n",
    "            'entr_O1': np.load(entropy_dir + patient + '_01_dispen.npy'),\n",
    "            'entr_M2': np.load(entropy_dir + patient + '_M2_dispen.npy'),\n",
    "                \n",
    "            'delta_E1': np.load(delta_dir + patient + '_chan_0.npy'),\n",
    "            'delta_E2': np.load(delta_dir + patient + '_chan_1.npy'), \n",
    "            'delta_F3': np.load(delta_dir + patient + '_chan_2.npy'),\n",
    "            'delta_C3': np.load(delta_dir + patient + '_chan_3.npy'),\n",
    "            'delta_O1': np.load(delta_dir + patient + '_chan_4.npy'),\n",
    "            'delta_M2': np.load(delta_dir + patient + '_chan_5.npy'),\n",
    "            \n",
    "            'theta_E1': np.load(theta_dir + patient + '_chan_0.npy'),\n",
    "            'theta_E2': np.load(theta_dir + patient + '_chan_1.npy'), \n",
    "            'theta_F3': np.load(theta_dir + patient + '_chan_2.npy'),\n",
    "            'theta_C3': np.load(theta_dir + patient + '_chan_3.npy'),\n",
    "            'theta_O1': np.load(theta_dir + patient + '_chan_4.npy'),\n",
    "            'theta_M2': np.load(theta_dir + patient + '_chan_5.npy'),\n",
    "            \n",
    "            'alpha_E1': np.load(alpha_dir + patient + '_chan_0.npy'),\n",
    "            'alpha_E2': np.load(alpha_dir + patient + '_chan_1.npy'), \n",
    "            'alpha_F3': np.load(alpha_dir + patient + '_chan_2.npy'),\n",
    "            'alpha_C3': np.load(alpha_dir + patient + '_chan_3.npy'),\n",
    "            'alpha_O1': np.load(alpha_dir + patient + '_chan_4.npy'),\n",
    "            'alpha_M2': np.load(alpha_dir + patient + '_chan_5.npy'),\n",
    "                \n",
    "            'beta_E1': np.load(beta_dir + patient + '_chan_0.npy'),\n",
    "            'beta_E2': np.load(beta_dir + patient + '_chan_1.npy'), \n",
    "            'beta_F3': np.load(beta_dir + patient + '_chan_2.npy'),\n",
    "            'beta_C3': np.load(beta_dir + patient + '_chan_3.npy'),\n",
    "            'beta_O1': np.load(beta_dir + patient + '_chan_4.npy'),\n",
    "            'beta_M2': np.load(beta_dir + patient + '_chan_5.npy'),\n",
    "                \n",
    "            'cc_E1_O1': np.load(cc_dir + patient + '_E1_O1.npy'),\n",
    "            'cc_E2_M2': np.load(cc_dir + patient + '_E2_M2.npy'),\n",
    "            'cc_C3_O1': np.load(cc_dir + patient + '_C3_O1.npy'),\n",
    "            'cc_E1_F3': np.load(cc_dir + patient + '_E1_F3.npy'),\n",
    "            'cc_F3_C3': np.load(cc_dir + patient + '_F3_C3.npy'),\n",
    "            'cc_E2_O1': np.load(cc_dir + patient + '_E2_O1.npy'),\n",
    "            'cc_E1_M2': np.load(cc_dir + patient + '_E1_M2.npy'),\n",
    "            'cc_C3_M2': np.load(cc_dir + patient + '_C3_M2.npy'),\n",
    "            'cc_F3_M2': np.load(cc_dir + patient + '_F3_M2.npy'),\n",
    "            'cc_E1_C3': np.load(cc_dir + patient + '_E1_C3.npy'),\n",
    "            'cc_E1_E2': np.load(cc_dir + patient + '_E1_E2.npy'),\n",
    "            'cc_E2_F3': np.load(cc_dir + patient + '_E2_F3.npy'),\n",
    "            'cc_F3_O1': np.load(cc_dir + patient + '_F3_O1.npy'),\n",
    "            'cc_O1_M2': np.load(cc_dir + patient + '_O1_M2.npy'),\n",
    "            'cc_E2_C3': np.load(cc_dir + patient + '_E2_C3.npy'),\n",
    "            \n",
    "                \n",
    "            'plv_E1_O1': np.load(plv_dir + patient + '_E1_O1.npy'),\n",
    "            'plv_E2_M2': np.load(plv_dir + patient + '_E2_M2.npy'),\n",
    "            'plv_C3_O1': np.load(plv_dir + patient + '_C3_O1.npy'),\n",
    "            'plv_E1_F3': np.load(plv_dir + patient + '_E1_F3.npy'),\n",
    "            'plv_F3_C3': np.load(plv_dir + patient + '_F3_C3.npy'),\n",
    "            'plv_E2_O1': np.load(plv_dir + patient + '_E2_O1.npy'),\n",
    "            'plv_E1_M2': np.load(plv_dir + patient + '_E1_M2.npy'),\n",
    "            'plv_C3_M2': np.load(plv_dir + patient + '_C3_M2.npy'),\n",
    "            'plv_F3_M2': np.load(plv_dir + patient + '_F3_M2.npy'),\n",
    "            'plv_E1_C3': np.load(plv_dir + patient + '_E1_C3.npy'),\n",
    "            'plv_E1_E2': np.load(plv_dir + patient + '_E1_E2.npy'),\n",
    "            'plv_E2_F3': np.load(plv_dir + patient + '_E2_F3.npy'),\n",
    "            'plv_F3_O1': np.load(plv_dir + patient + '_F3_O1.npy'),\n",
    "            'plv_O1_M2': np.load(plv_dir + patient + '_O1_M2.npy'),\n",
    "            'plv_E2_C3': np.load(plv_dir + patient + '_E2_C3.npy')}\n",
    "\n",
    "\n",
    "        data_df = pd.DataFrame(data = data_dict)\n",
    "        all_patients.append(data_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "02fcfb38",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_patients_concat = pd.concat(all_patients)\n",
    "all_patients_concat['Patient_ID'] = all_patients_concat['Patient_ID'].str.split().str[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "37d400a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine the two lists and create a list of labels (0 for human_wt and 1 for human_gap)\n",
    "all_ids = np.unique(all_patients_concat['Patient_ID'].to_list())\n",
    "labels = [0] * len(human_wt) + [1] * len(human_gap)\n",
    "\n",
    "# Split the combined list into training and test sets, stratifying by the labels\n",
    "train_ids, test_ids,_, _ = train_test_split(all_ids, labels, test_size=0.3, stratify=labels, random_state= 7) #7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "61cbb7bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "human_wt = ['P1', 'P11', 'P17', 'P18', 'P21', 'P24', 'P27','P28', 'P29', 'P4']\n",
    "human_gap = ['P3','P10', 'P15', 'P16', 'P2', 'P5', 'P6', 'P7','P8', 'P20',  'P22',\n",
    "            'P23', 'P30'] \n",
    "# Create a dictionary mapping IDs to genotype\n",
    "genotype_dict = {id: 0 for id in human_wt}\n",
    "genotype_dict.update({id: 1 for id in human_gap})\n",
    "\n",
    "# Map the genotype to each ID\n",
    "all_patients_concat['Genotype'] = all_patients_concat['Patient_ID'].map(genotype_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0347264c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Genotype</th>\n",
       "      <th>Patient_ID</th>\n",
       "      <th>hfd_E1</th>\n",
       "      <th>hfd_E2</th>\n",
       "      <th>hfd_F3</th>\n",
       "      <th>hfd_C3</th>\n",
       "      <th>hfd_O1</th>\n",
       "      <th>hfd_M2</th>\n",
       "      <th>hurst_E1</th>\n",
       "      <th>hurst_E2</th>\n",
       "      <th>...</th>\n",
       "      <th>plv_E2_O1</th>\n",
       "      <th>plv_E1_M2</th>\n",
       "      <th>plv_C3_M2</th>\n",
       "      <th>plv_F3_M2</th>\n",
       "      <th>plv_E1_C3</th>\n",
       "      <th>plv_E1_E2</th>\n",
       "      <th>plv_E2_F3</th>\n",
       "      <th>plv_F3_O1</th>\n",
       "      <th>plv_O1_M2</th>\n",
       "      <th>plv_E2_C3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>P1</td>\n",
       "      <td>1.259010</td>\n",
       "      <td>1.287560</td>\n",
       "      <td>1.345742</td>\n",
       "      <td>1.404019</td>\n",
       "      <td>1.360719</td>\n",
       "      <td>1.180604</td>\n",
       "      <td>5.618996</td>\n",
       "      <td>4.948972</td>\n",
       "      <td>...</td>\n",
       "      <td>0.136559</td>\n",
       "      <td>0.066617</td>\n",
       "      <td>0.317614</td>\n",
       "      <td>0.219175</td>\n",
       "      <td>0.031050</td>\n",
       "      <td>0.094453</td>\n",
       "      <td>0.114246</td>\n",
       "      <td>0.361783</td>\n",
       "      <td>0.463639</td>\n",
       "      <td>0.460349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>P1</td>\n",
       "      <td>1.288518</td>\n",
       "      <td>1.295109</td>\n",
       "      <td>1.390928</td>\n",
       "      <td>1.525738</td>\n",
       "      <td>1.423083</td>\n",
       "      <td>1.198804</td>\n",
       "      <td>1.124914</td>\n",
       "      <td>0.637460</td>\n",
       "      <td>...</td>\n",
       "      <td>0.133731</td>\n",
       "      <td>0.063147</td>\n",
       "      <td>0.323628</td>\n",
       "      <td>0.222661</td>\n",
       "      <td>0.049408</td>\n",
       "      <td>0.104039</td>\n",
       "      <td>0.115528</td>\n",
       "      <td>0.368201</td>\n",
       "      <td>0.464346</td>\n",
       "      <td>0.465072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>P1</td>\n",
       "      <td>1.271529</td>\n",
       "      <td>1.288301</td>\n",
       "      <td>1.359896</td>\n",
       "      <td>1.473247</td>\n",
       "      <td>1.382110</td>\n",
       "      <td>1.193684</td>\n",
       "      <td>1.105576</td>\n",
       "      <td>0.663885</td>\n",
       "      <td>...</td>\n",
       "      <td>0.132982</td>\n",
       "      <td>0.042809</td>\n",
       "      <td>0.314715</td>\n",
       "      <td>0.214867</td>\n",
       "      <td>0.062003</td>\n",
       "      <td>0.079305</td>\n",
       "      <td>0.118392</td>\n",
       "      <td>0.376463</td>\n",
       "      <td>0.473112</td>\n",
       "      <td>0.459087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>P1</td>\n",
       "      <td>1.236841</td>\n",
       "      <td>1.265465</td>\n",
       "      <td>1.339673</td>\n",
       "      <td>1.499912</td>\n",
       "      <td>1.390660</td>\n",
       "      <td>1.203013</td>\n",
       "      <td>1.092913</td>\n",
       "      <td>0.707510</td>\n",
       "      <td>...</td>\n",
       "      <td>0.143173</td>\n",
       "      <td>0.024619</td>\n",
       "      <td>0.300504</td>\n",
       "      <td>0.229108</td>\n",
       "      <td>0.029892</td>\n",
       "      <td>0.065242</td>\n",
       "      <td>0.102945</td>\n",
       "      <td>0.379929</td>\n",
       "      <td>0.472624</td>\n",
       "      <td>0.451525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>P1</td>\n",
       "      <td>1.288130</td>\n",
       "      <td>1.276510</td>\n",
       "      <td>1.355095</td>\n",
       "      <td>1.449566</td>\n",
       "      <td>1.366411</td>\n",
       "      <td>1.183505</td>\n",
       "      <td>0.533325</td>\n",
       "      <td>0.664026</td>\n",
       "      <td>...</td>\n",
       "      <td>0.143806</td>\n",
       "      <td>0.047474</td>\n",
       "      <td>0.308595</td>\n",
       "      <td>0.229667</td>\n",
       "      <td>0.030912</td>\n",
       "      <td>0.063451</td>\n",
       "      <td>0.112550</td>\n",
       "      <td>0.383810</td>\n",
       "      <td>0.475708</td>\n",
       "      <td>0.444778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>1</td>\n",
       "      <td>P30</td>\n",
       "      <td>1.168026</td>\n",
       "      <td>1.203240</td>\n",
       "      <td>1.139592</td>\n",
       "      <td>1.224856</td>\n",
       "      <td>1.165637</td>\n",
       "      <td>1.173075</td>\n",
       "      <td>1.915751</td>\n",
       "      <td>0.698487</td>\n",
       "      <td>...</td>\n",
       "      <td>0.405485</td>\n",
       "      <td>0.044007</td>\n",
       "      <td>0.314910</td>\n",
       "      <td>0.204122</td>\n",
       "      <td>0.161259</td>\n",
       "      <td>0.052143</td>\n",
       "      <td>0.299697</td>\n",
       "      <td>0.414587</td>\n",
       "      <td>0.639142</td>\n",
       "      <td>0.210409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>1</td>\n",
       "      <td>P30</td>\n",
       "      <td>1.078418</td>\n",
       "      <td>1.129098</td>\n",
       "      <td>1.088168</td>\n",
       "      <td>1.144734</td>\n",
       "      <td>1.091198</td>\n",
       "      <td>1.172230</td>\n",
       "      <td>-1.491164</td>\n",
       "      <td>0.568341</td>\n",
       "      <td>...</td>\n",
       "      <td>0.367554</td>\n",
       "      <td>0.083375</td>\n",
       "      <td>0.188865</td>\n",
       "      <td>0.223397</td>\n",
       "      <td>0.171441</td>\n",
       "      <td>0.051632</td>\n",
       "      <td>0.271316</td>\n",
       "      <td>0.413159</td>\n",
       "      <td>0.633854</td>\n",
       "      <td>0.215399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>1</td>\n",
       "      <td>P30</td>\n",
       "      <td>1.074318</td>\n",
       "      <td>1.084992</td>\n",
       "      <td>1.082618</td>\n",
       "      <td>1.123976</td>\n",
       "      <td>1.086916</td>\n",
       "      <td>1.176893</td>\n",
       "      <td>2.680879</td>\n",
       "      <td>0.672771</td>\n",
       "      <td>...</td>\n",
       "      <td>0.400989</td>\n",
       "      <td>0.128285</td>\n",
       "      <td>0.141484</td>\n",
       "      <td>0.203109</td>\n",
       "      <td>0.152830</td>\n",
       "      <td>0.062022</td>\n",
       "      <td>0.261363</td>\n",
       "      <td>0.403097</td>\n",
       "      <td>0.645940</td>\n",
       "      <td>0.206118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>1</td>\n",
       "      <td>P30</td>\n",
       "      <td>1.081765</td>\n",
       "      <td>1.081582</td>\n",
       "      <td>1.104193</td>\n",
       "      <td>1.175438</td>\n",
       "      <td>1.111038</td>\n",
       "      <td>1.182510</td>\n",
       "      <td>0.979190</td>\n",
       "      <td>0.583480</td>\n",
       "      <td>...</td>\n",
       "      <td>0.482562</td>\n",
       "      <td>0.147136</td>\n",
       "      <td>0.136503</td>\n",
       "      <td>0.137870</td>\n",
       "      <td>0.114960</td>\n",
       "      <td>0.068522</td>\n",
       "      <td>0.241188</td>\n",
       "      <td>0.389068</td>\n",
       "      <td>0.661136</td>\n",
       "      <td>0.208241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>1</td>\n",
       "      <td>P30</td>\n",
       "      <td>1.070420</td>\n",
       "      <td>1.074232</td>\n",
       "      <td>1.091783</td>\n",
       "      <td>1.142304</td>\n",
       "      <td>1.100292</td>\n",
       "      <td>1.172466</td>\n",
       "      <td>1.039746</td>\n",
       "      <td>0.484071</td>\n",
       "      <td>...</td>\n",
       "      <td>0.228888</td>\n",
       "      <td>0.039608</td>\n",
       "      <td>0.192477</td>\n",
       "      <td>0.019385</td>\n",
       "      <td>0.044698</td>\n",
       "      <td>0.190989</td>\n",
       "      <td>0.174751</td>\n",
       "      <td>0.519518</td>\n",
       "      <td>0.717767</td>\n",
       "      <td>0.423861</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5755 rows × 74 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Genotype Patient_ID    hfd_E1    hfd_E2    hfd_F3    hfd_C3    hfd_O1  \\\n",
       "0           0         P1  1.259010  1.287560  1.345742  1.404019  1.360719   \n",
       "1           0         P1  1.288518  1.295109  1.390928  1.525738  1.423083   \n",
       "2           0         P1  1.271529  1.288301  1.359896  1.473247  1.382110   \n",
       "3           0         P1  1.236841  1.265465  1.339673  1.499912  1.390660   \n",
       "4           0         P1  1.288130  1.276510  1.355095  1.449566  1.366411   \n",
       "..        ...        ...       ...       ...       ...       ...       ...   \n",
       "168         1        P30  1.168026  1.203240  1.139592  1.224856  1.165637   \n",
       "169         1        P30  1.078418  1.129098  1.088168  1.144734  1.091198   \n",
       "170         1        P30  1.074318  1.084992  1.082618  1.123976  1.086916   \n",
       "171         1        P30  1.081765  1.081582  1.104193  1.175438  1.111038   \n",
       "172         1        P30  1.070420  1.074232  1.091783  1.142304  1.100292   \n",
       "\n",
       "       hfd_M2  hurst_E1  hurst_E2  ...  plv_E2_O1  plv_E1_M2  plv_C3_M2  \\\n",
       "0    1.180604  5.618996  4.948972  ...   0.136559   0.066617   0.317614   \n",
       "1    1.198804  1.124914  0.637460  ...   0.133731   0.063147   0.323628   \n",
       "2    1.193684  1.105576  0.663885  ...   0.132982   0.042809   0.314715   \n",
       "3    1.203013  1.092913  0.707510  ...   0.143173   0.024619   0.300504   \n",
       "4    1.183505  0.533325  0.664026  ...   0.143806   0.047474   0.308595   \n",
       "..        ...       ...       ...  ...        ...        ...        ...   \n",
       "168  1.173075  1.915751  0.698487  ...   0.405485   0.044007   0.314910   \n",
       "169  1.172230 -1.491164  0.568341  ...   0.367554   0.083375   0.188865   \n",
       "170  1.176893  2.680879  0.672771  ...   0.400989   0.128285   0.141484   \n",
       "171  1.182510  0.979190  0.583480  ...   0.482562   0.147136   0.136503   \n",
       "172  1.172466  1.039746  0.484071  ...   0.228888   0.039608   0.192477   \n",
       "\n",
       "     plv_F3_M2  plv_E1_C3  plv_E1_E2  plv_E2_F3  plv_F3_O1  plv_O1_M2  \\\n",
       "0     0.219175   0.031050   0.094453   0.114246   0.361783   0.463639   \n",
       "1     0.222661   0.049408   0.104039   0.115528   0.368201   0.464346   \n",
       "2     0.214867   0.062003   0.079305   0.118392   0.376463   0.473112   \n",
       "3     0.229108   0.029892   0.065242   0.102945   0.379929   0.472624   \n",
       "4     0.229667   0.030912   0.063451   0.112550   0.383810   0.475708   \n",
       "..         ...        ...        ...        ...        ...        ...   \n",
       "168   0.204122   0.161259   0.052143   0.299697   0.414587   0.639142   \n",
       "169   0.223397   0.171441   0.051632   0.271316   0.413159   0.633854   \n",
       "170   0.203109   0.152830   0.062022   0.261363   0.403097   0.645940   \n",
       "171   0.137870   0.114960   0.068522   0.241188   0.389068   0.661136   \n",
       "172   0.019385   0.044698   0.190989   0.174751   0.519518   0.717767   \n",
       "\n",
       "     plv_E2_C3  \n",
       "0     0.460349  \n",
       "1     0.465072  \n",
       "2     0.459087  \n",
       "3     0.451525  \n",
       "4     0.444778  \n",
       "..         ...  \n",
       "168   0.210409  \n",
       "169   0.215399  \n",
       "170   0.206118  \n",
       "171   0.208241  \n",
       "172   0.423861  \n",
       "\n",
       "[5755 rows x 74 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = all_patients_concat[['Genotype'] + [col for col in all_patients_concat.columns if col != 'Genotype']]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c1dd13a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df[df[\"Patient_ID\"].isin(train_ids)]\n",
    "X_test = df[df[\"Patient_ID\"].isin(test_ids)]\n",
    "X_train_new = X_train.iloc[:, 2:]\n",
    "X_test_new = X_test.iloc[:, 2:]\n",
    "y_train = X_train.iloc[:, 0]\n",
    "y_test = X_test.iloc[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4aaeec51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['P1', 'P1', 'P1', ..., 'P29', 'P29', 'P29'], dtype=object)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "group_by_patient_id = X_train.groupby(['Patient_ID'])\n",
    "groups_by_patient_id_list = np.array(X_train['Patient_ID'].values)\n",
    "groups_by_patient_id_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0a2eafbb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hfd_E1</th>\n",
       "      <th>hfd_E2</th>\n",
       "      <th>hfd_F3</th>\n",
       "      <th>hfd_C3</th>\n",
       "      <th>hfd_O1</th>\n",
       "      <th>hfd_M2</th>\n",
       "      <th>hurst_E1</th>\n",
       "      <th>hurst_E2</th>\n",
       "      <th>hurst_F3</th>\n",
       "      <th>hurst_C3</th>\n",
       "      <th>...</th>\n",
       "      <th>plv_E2_O1</th>\n",
       "      <th>plv_E1_M2</th>\n",
       "      <th>plv_C3_M2</th>\n",
       "      <th>plv_F3_M2</th>\n",
       "      <th>plv_E1_C3</th>\n",
       "      <th>plv_E1_E2</th>\n",
       "      <th>plv_E2_F3</th>\n",
       "      <th>plv_F3_O1</th>\n",
       "      <th>plv_O1_M2</th>\n",
       "      <th>plv_E2_C3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.259010</td>\n",
       "      <td>1.287560</td>\n",
       "      <td>1.345742</td>\n",
       "      <td>1.404019</td>\n",
       "      <td>1.360719</td>\n",
       "      <td>1.180604</td>\n",
       "      <td>5.618996</td>\n",
       "      <td>4.948972</td>\n",
       "      <td>3.917417</td>\n",
       "      <td>4.668170</td>\n",
       "      <td>...</td>\n",
       "      <td>0.136559</td>\n",
       "      <td>0.066617</td>\n",
       "      <td>0.317614</td>\n",
       "      <td>0.219175</td>\n",
       "      <td>0.031050</td>\n",
       "      <td>0.094453</td>\n",
       "      <td>0.114246</td>\n",
       "      <td>0.361783</td>\n",
       "      <td>0.463639</td>\n",
       "      <td>0.460349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.288518</td>\n",
       "      <td>1.295109</td>\n",
       "      <td>1.390928</td>\n",
       "      <td>1.525738</td>\n",
       "      <td>1.423083</td>\n",
       "      <td>1.198804</td>\n",
       "      <td>1.124914</td>\n",
       "      <td>0.637460</td>\n",
       "      <td>0.684166</td>\n",
       "      <td>0.796270</td>\n",
       "      <td>...</td>\n",
       "      <td>0.133731</td>\n",
       "      <td>0.063147</td>\n",
       "      <td>0.323628</td>\n",
       "      <td>0.222661</td>\n",
       "      <td>0.049408</td>\n",
       "      <td>0.104039</td>\n",
       "      <td>0.115528</td>\n",
       "      <td>0.368201</td>\n",
       "      <td>0.464346</td>\n",
       "      <td>0.465072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.271529</td>\n",
       "      <td>1.288301</td>\n",
       "      <td>1.359896</td>\n",
       "      <td>1.473247</td>\n",
       "      <td>1.382110</td>\n",
       "      <td>1.193684</td>\n",
       "      <td>1.105576</td>\n",
       "      <td>0.663885</td>\n",
       "      <td>0.693960</td>\n",
       "      <td>0.731726</td>\n",
       "      <td>...</td>\n",
       "      <td>0.132982</td>\n",
       "      <td>0.042809</td>\n",
       "      <td>0.314715</td>\n",
       "      <td>0.214867</td>\n",
       "      <td>0.062003</td>\n",
       "      <td>0.079305</td>\n",
       "      <td>0.118392</td>\n",
       "      <td>0.376463</td>\n",
       "      <td>0.473112</td>\n",
       "      <td>0.459087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.236841</td>\n",
       "      <td>1.265465</td>\n",
       "      <td>1.339673</td>\n",
       "      <td>1.499912</td>\n",
       "      <td>1.390660</td>\n",
       "      <td>1.203013</td>\n",
       "      <td>1.092913</td>\n",
       "      <td>0.707510</td>\n",
       "      <td>0.698831</td>\n",
       "      <td>0.724703</td>\n",
       "      <td>...</td>\n",
       "      <td>0.143173</td>\n",
       "      <td>0.024619</td>\n",
       "      <td>0.300504</td>\n",
       "      <td>0.229108</td>\n",
       "      <td>0.029892</td>\n",
       "      <td>0.065242</td>\n",
       "      <td>0.102945</td>\n",
       "      <td>0.379929</td>\n",
       "      <td>0.472624</td>\n",
       "      <td>0.451525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.288130</td>\n",
       "      <td>1.276510</td>\n",
       "      <td>1.355095</td>\n",
       "      <td>1.449566</td>\n",
       "      <td>1.366411</td>\n",
       "      <td>1.183505</td>\n",
       "      <td>0.533325</td>\n",
       "      <td>0.664026</td>\n",
       "      <td>0.684062</td>\n",
       "      <td>0.688491</td>\n",
       "      <td>...</td>\n",
       "      <td>0.143806</td>\n",
       "      <td>0.047474</td>\n",
       "      <td>0.308595</td>\n",
       "      <td>0.229667</td>\n",
       "      <td>0.030912</td>\n",
       "      <td>0.063451</td>\n",
       "      <td>0.112550</td>\n",
       "      <td>0.383810</td>\n",
       "      <td>0.475708</td>\n",
       "      <td>0.444778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>1.243609</td>\n",
       "      <td>1.253963</td>\n",
       "      <td>1.451482</td>\n",
       "      <td>1.200820</td>\n",
       "      <td>1.210384</td>\n",
       "      <td>1.193797</td>\n",
       "      <td>0.921943</td>\n",
       "      <td>0.717147</td>\n",
       "      <td>0.659586</td>\n",
       "      <td>0.293366</td>\n",
       "      <td>...</td>\n",
       "      <td>0.039859</td>\n",
       "      <td>0.080778</td>\n",
       "      <td>0.006947</td>\n",
       "      <td>0.096422</td>\n",
       "      <td>0.098606</td>\n",
       "      <td>0.141406</td>\n",
       "      <td>0.076996</td>\n",
       "      <td>0.151052</td>\n",
       "      <td>0.174233</td>\n",
       "      <td>0.247354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>1.200461</td>\n",
       "      <td>1.247358</td>\n",
       "      <td>1.381587</td>\n",
       "      <td>1.148555</td>\n",
       "      <td>1.302820</td>\n",
       "      <td>1.175062</td>\n",
       "      <td>0.865808</td>\n",
       "      <td>0.641022</td>\n",
       "      <td>0.659633</td>\n",
       "      <td>0.309209</td>\n",
       "      <td>...</td>\n",
       "      <td>0.036311</td>\n",
       "      <td>0.105189</td>\n",
       "      <td>0.178515</td>\n",
       "      <td>0.012051</td>\n",
       "      <td>0.078402</td>\n",
       "      <td>0.187620</td>\n",
       "      <td>0.057760</td>\n",
       "      <td>0.269337</td>\n",
       "      <td>0.317518</td>\n",
       "      <td>0.148407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>1.207714</td>\n",
       "      <td>1.258099</td>\n",
       "      <td>1.446536</td>\n",
       "      <td>1.293801</td>\n",
       "      <td>1.430410</td>\n",
       "      <td>1.178000</td>\n",
       "      <td>0.562495</td>\n",
       "      <td>0.589333</td>\n",
       "      <td>0.599613</td>\n",
       "      <td>0.276598</td>\n",
       "      <td>...</td>\n",
       "      <td>0.087500</td>\n",
       "      <td>0.037254</td>\n",
       "      <td>0.048657</td>\n",
       "      <td>0.067028</td>\n",
       "      <td>0.095765</td>\n",
       "      <td>0.155932</td>\n",
       "      <td>0.033899</td>\n",
       "      <td>0.276249</td>\n",
       "      <td>0.277919</td>\n",
       "      <td>0.120870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>1.181486</td>\n",
       "      <td>1.159492</td>\n",
       "      <td>1.457857</td>\n",
       "      <td>1.171927</td>\n",
       "      <td>1.478491</td>\n",
       "      <td>1.188670</td>\n",
       "      <td>0.830973</td>\n",
       "      <td>0.526392</td>\n",
       "      <td>0.583102</td>\n",
       "      <td>0.423214</td>\n",
       "      <td>...</td>\n",
       "      <td>0.049072</td>\n",
       "      <td>0.128866</td>\n",
       "      <td>0.101133</td>\n",
       "      <td>0.115517</td>\n",
       "      <td>0.027759</td>\n",
       "      <td>0.166507</td>\n",
       "      <td>0.050836</td>\n",
       "      <td>0.229444</td>\n",
       "      <td>0.250817</td>\n",
       "      <td>0.161220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>1.252955</td>\n",
       "      <td>1.342218</td>\n",
       "      <td>1.427312</td>\n",
       "      <td>1.235874</td>\n",
       "      <td>1.485963</td>\n",
       "      <td>1.213297</td>\n",
       "      <td>0.855094</td>\n",
       "      <td>0.664070</td>\n",
       "      <td>0.711372</td>\n",
       "      <td>0.453898</td>\n",
       "      <td>...</td>\n",
       "      <td>0.020456</td>\n",
       "      <td>0.114698</td>\n",
       "      <td>0.135722</td>\n",
       "      <td>0.137659</td>\n",
       "      <td>0.063333</td>\n",
       "      <td>0.095685</td>\n",
       "      <td>0.053719</td>\n",
       "      <td>0.256546</td>\n",
       "      <td>0.255496</td>\n",
       "      <td>0.168642</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4646 rows × 72 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      hfd_E1    hfd_E2    hfd_F3    hfd_C3    hfd_O1    hfd_M2  hurst_E1  \\\n",
       "0   1.259010  1.287560  1.345742  1.404019  1.360719  1.180604  5.618996   \n",
       "1   1.288518  1.295109  1.390928  1.525738  1.423083  1.198804  1.124914   \n",
       "2   1.271529  1.288301  1.359896  1.473247  1.382110  1.193684  1.105576   \n",
       "3   1.236841  1.265465  1.339673  1.499912  1.390660  1.203013  1.092913   \n",
       "4   1.288130  1.276510  1.355095  1.449566  1.366411  1.183505  0.533325   \n",
       "..       ...       ...       ...       ...       ...       ...       ...   \n",
       "60  1.243609  1.253963  1.451482  1.200820  1.210384  1.193797  0.921943   \n",
       "61  1.200461  1.247358  1.381587  1.148555  1.302820  1.175062  0.865808   \n",
       "62  1.207714  1.258099  1.446536  1.293801  1.430410  1.178000  0.562495   \n",
       "63  1.181486  1.159492  1.457857  1.171927  1.478491  1.188670  0.830973   \n",
       "64  1.252955  1.342218  1.427312  1.235874  1.485963  1.213297  0.855094   \n",
       "\n",
       "    hurst_E2  hurst_F3  hurst_C3  ...  plv_E2_O1  plv_E1_M2  plv_C3_M2  \\\n",
       "0   4.948972  3.917417  4.668170  ...   0.136559   0.066617   0.317614   \n",
       "1   0.637460  0.684166  0.796270  ...   0.133731   0.063147   0.323628   \n",
       "2   0.663885  0.693960  0.731726  ...   0.132982   0.042809   0.314715   \n",
       "3   0.707510  0.698831  0.724703  ...   0.143173   0.024619   0.300504   \n",
       "4   0.664026  0.684062  0.688491  ...   0.143806   0.047474   0.308595   \n",
       "..       ...       ...       ...  ...        ...        ...        ...   \n",
       "60  0.717147  0.659586  0.293366  ...   0.039859   0.080778   0.006947   \n",
       "61  0.641022  0.659633  0.309209  ...   0.036311   0.105189   0.178515   \n",
       "62  0.589333  0.599613  0.276598  ...   0.087500   0.037254   0.048657   \n",
       "63  0.526392  0.583102  0.423214  ...   0.049072   0.128866   0.101133   \n",
       "64  0.664070  0.711372  0.453898  ...   0.020456   0.114698   0.135722   \n",
       "\n",
       "    plv_F3_M2  plv_E1_C3  plv_E1_E2  plv_E2_F3  plv_F3_O1  plv_O1_M2  \\\n",
       "0    0.219175   0.031050   0.094453   0.114246   0.361783   0.463639   \n",
       "1    0.222661   0.049408   0.104039   0.115528   0.368201   0.464346   \n",
       "2    0.214867   0.062003   0.079305   0.118392   0.376463   0.473112   \n",
       "3    0.229108   0.029892   0.065242   0.102945   0.379929   0.472624   \n",
       "4    0.229667   0.030912   0.063451   0.112550   0.383810   0.475708   \n",
       "..        ...        ...        ...        ...        ...        ...   \n",
       "60   0.096422   0.098606   0.141406   0.076996   0.151052   0.174233   \n",
       "61   0.012051   0.078402   0.187620   0.057760   0.269337   0.317518   \n",
       "62   0.067028   0.095765   0.155932   0.033899   0.276249   0.277919   \n",
       "63   0.115517   0.027759   0.166507   0.050836   0.229444   0.250817   \n",
       "64   0.137659   0.063333   0.095685   0.053719   0.256546   0.255496   \n",
       "\n",
       "    plv_E2_C3  \n",
       "0    0.460349  \n",
       "1    0.465072  \n",
       "2    0.459087  \n",
       "3    0.451525  \n",
       "4    0.444778  \n",
       "..        ...  \n",
       "60   0.247354  \n",
       "61   0.148407  \n",
       "62   0.120870  \n",
       "63   0.161220  \n",
       "64   0.168642  \n",
       "\n",
       "[4646 rows x 72 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "841b865f",
   "metadata": {},
   "outputs": [],
   "source": [
    "accepted_features = ['hfd_E1', 'theta_E1', 'plv_F3_C3', 'plv_O1_M2', 'beta_F3',\n",
    "                     'beta_C3', 'beta_E2', 'theta_O1', 'alpha_C3', 'beta_E1',\n",
    "                     'cc_E1_E2', 'theta_M2', 'cc_E1_M2', 'plv_C3_O1', 'plv_E1_F3',\n",
    "                     'cc_E1_F3', 'plv_F3_M2', 'plv_E2_M2', 'plv_E1_E2', 'delta_M2',\n",
    "                     'hfd_E2', 'alpha_E1', 'cc_E1_C3', 'hfd_F3', 'alpha_E2', 'plv_E2_F3',\n",
    "                     'plv_F3_O1', 'beta_M2', 'cc_F3_C3', 'cc_E1_O1', 'theta_E2', 'alpha_M2',\n",
    "                     'cc_O1_M2', 'plv_E1_O1', 'cc_C3_M2', 'cc_E2_O1', 'cc_F3_M2', 'plv_C3_M2',\n",
    "                     'entr_C3', 'plv_E2_C3', 'theta_C3', 'cc_E2_F3', 'hfd_M2', 'cc_E2_C3',\n",
    "                     'plv_E2_O1', 'cc_C3_O1', 'cc_F3_O1', 'beta_O1']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "08c24093",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_acc = X_train_new[accepted_features]\n",
    "X_test_acc = X_test_new[accepted_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "cfa6aa22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "n_splits = 3\n",
    "group_kfold = GroupKFold(n_splits = n_splits)\n",
    "print(group_kfold.get_n_splits(X_train_acc, y_train, groups = groups_by_patient_id_list))\n",
    "\n",
    "result = []\n",
    "y_result = []\n",
    "for train_idx, val_idx in group_kfold.split(X_train_acc, y_train, groups = groups_by_patient_id_list):\n",
    "    train_fold = X_train_acc.iloc[train_idx]\n",
    "    val_fold = X_train_acc.iloc[val_idx]\n",
    "    train_y_fold = y_train.iloc[train_idx]\n",
    "    val_y_fold = y_train.iloc[val_idx]\n",
    "    result.append((train_fold, val_fold))\n",
    "    y_result.append((train_y_fold, val_y_fold))\n",
    "    \n",
    "train_fold_1, val_fold_1 = result[0][0],result[0][1]\n",
    "train_fold_2, val_fold_2 = result[1][0],result[1][1]\n",
    "train_fold_3, val_fold_3 = result[2][0],result[2][1]\n",
    "\n",
    "\n",
    "y_train_fold_1, y_val_fold_1 = y_result[0][0],y_result[0][1]\n",
    "y_train_fold_2, y_val_fold_2 = y_result[1][0],y_result[1][1]\n",
    "y_train_fold_3, y_val_fold_3 = y_result[2][0],y_result[2][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "39faca6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "options = {\n",
    "    'max_depth': hp.quniform('max_depth', 1, 8, 1),\n",
    "    'min_child_weight': hp.loguniform('min_child_weight', -2, 3),\n",
    "    'subsample': hp.uniform('subsample', 0.5, 1),\n",
    "    'colsample_bytree': hp.uniform('colsample_bytree', 0.5, 1),\n",
    "    'reg_alpha': hp.uniform('reg_alpha', 0, 10),\n",
    "    'reg_lambda': hp.uniform('reg_lambda', 1, 10),\n",
    "    'gamma': hp.loguniform('gamma', -10, 10),\n",
    "    'learning_rate': hp.loguniform('learning_rate', -7, 0),\n",
    "    'n_estimators': hp.choice('n_estimators', range(50, 1001, 50)),\n",
    "    'scale_pos_weight': hp.uniform('scale_pos_weight', 1, 100),\n",
    "    'max_delta_step': hp.quniform('max_delta_step', 0, 10, 1),\n",
    "    'tree_method': 'exact', \n",
    "    #'sample_type': hp.choice('sample_type', ['uniform', 'weighted']),\n",
    "    #'normalize_type': hp.choice('normalize_type', ['tree', 'forest']),\n",
    "    #'rate_drop': hp.uniform('rate_drop', 0, 1),\n",
    "    #'skip_drop': hp.uniform('skip_drop', 0, 1),\n",
    "    'random_state': 7\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "fde88193",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hyperparameter_tuning(space: Dict[str, Union[float, int]],\n",
    "                         X_train: pd.DataFrame, y_train: pd.Series, \n",
    "                         X_test: pd.DataFrame, y_test: pd.Series, \n",
    "                         early_stopping_rounds: int = 50, \n",
    "                         metric: callable = roc_auc_score) -> Dict[str, Any]:\n",
    "    \n",
    "    '''Perform hyperparameter runing for an XGBoost classifier. \n",
    "    \n",
    "    This function takes a dictionary of hyperparameters, training and test data, and an optional value\n",
    "    for early stopping rounds, and returns a dictionary with the loss and model resulting from \n",
    "    the tuning process. The model is trained using the training data and evaluated on the test \n",
    "    data. The loss is computed as the negative of the accuracy score.\n",
    "    \n",
    "    space: Dict[str, Union[float, int]]\n",
    "    A dictionary of hyperparameters for the XGBoost classifier\n",
    "    \n",
    "    X_train: pd.DataFrame\n",
    "    The training data\n",
    "    \n",
    "    y_train: pd.Series\n",
    "    The training target\n",
    "    \n",
    "    X_test: pd.Dataframe\n",
    "    The test data\n",
    "    \n",
    "    y_test: pd.Series\n",
    "    The test target\n",
    "    \n",
    "    early_stopping rounds: int, optional \n",
    "    The number of early stopping rounds to use. The deault is 50\n",
    "    \n",
    "    metric: callable\n",
    "    Metric to maximise. Default is accuracy\n",
    "    \n",
    "    Returns: \n",
    "    Dict[str, Any]\n",
    "        A dictionary with the loss and model resulting from the tuning process. \n",
    "        The loss is a float, and the model is an XGBoost classifier'''\n",
    "    \n",
    "    int_vals = ['max_depth', 'reg_alpha']\n",
    "    \n",
    "    space = {k: (int(val) if k in int_vals else val)\n",
    "            for k, val in space.items()}\n",
    "    \n",
    "    space['early_stopping_rounds'] = early_stopping_rounds\n",
    "    \n",
    "    model = xgb.XGBClassifier( **space)\n",
    "    evaluation = [(X_train, y_train), \n",
    "                 (X_test, y_test)]\n",
    "    model.fit(X_train, y_train, eval_set = evaluation, verbose = False)\n",
    "    \n",
    "    score = metrics.roc_auc_score(y_test, model.predict(X_test))\n",
    "    return {'loss': -score, 'status': STATUS_OK, 'model': model}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5b0f654e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(['F3_C3_cross_corr', 'E2_M2_phase_lock', 'C3_M2_phase_lock', 'E2_F3_cross_corr', \n",
    "           'E2_M2_cross_corr', 'F3_M2_cross_corr', 'E2_C3_phase_lock', 'F3_C3_phase_lock',\n",
    "           'theta_F3', 'beta_O1', 'Hurst_E1', 'Dispen_O1', 'E1_M2_cross_corr', 'E1_O1_cross_corr',\n",
    "           'E1_C3_cross_corr', 'delta_M2', 'Hurst_F3', 'delta_E1', 'E1_M2_phase_lock', 'F3_M2_phase_lock',\n",
    "           'E2_F3_phase_lock', 'C3_M2_cross_corr', 'Dispen_C3', 'E2_O1_cross_corr', 'O1_M2_phase_lock',\n",
    "           'C3_O1_cross_corr', 'E1_E2_cross_corr', 'Dispen_E1', 'E2_O1_phase_lock'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0f86057a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████| 250/250 [00:49<00:00,  5.02trial/s, best loss: -0.7481334224693008]\n"
     ]
    }
   ],
   "source": [
    "trials = Trials()\n",
    "best_1 = fmin(fn = lambda space: hyperparameter_tuning(space, X_train = train_fold_1, y_train = y_train_fold_1,\n",
    "                                                     X_test = val_fold_1, y_test = y_val_fold_1),\n",
    "            space = options,\n",
    "            algo = tpe.suggest,\n",
    "            max_evals = 250,\n",
    "            trials = trials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "81152e11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 84%|█████ | 210/250 [00:44<00:08,  4.74trial/s, best loss: -0.7063342926865617]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[38], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m trials \u001b[38;5;241m=\u001b[39m Trials()\n\u001b[0;32m----> 2\u001b[0m best_2 \u001b[38;5;241m=\u001b[39m \u001b[43mfmin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mspace\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mhyperparameter_tuning\u001b[49m\u001b[43m(\u001b[49m\u001b[43mspace\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtrain_fold_2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43my_train_fold_2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m                                                     \u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mval_fold_2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43my_val_fold_2\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m            \u001b[49m\u001b[43mspace\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m            \u001b[49m\u001b[43malgo\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtpe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msuggest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmax_evals\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m250\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtrials\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtrials\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/hyperopt/fmin.py:540\u001b[0m, in \u001b[0;36mfmin\u001b[0;34m(fn, space, algo, max_evals, timeout, loss_threshold, trials, rstate, allow_trials_fmin, pass_expr_memo_ctrl, catch_eval_exceptions, verbose, return_argmin, points_to_evaluate, max_queue_len, show_progressbar, early_stop_fn, trials_save_file)\u001b[0m\n\u001b[1;32m    537\u001b[0m     fn \u001b[38;5;241m=\u001b[39m __objective_fmin_wrapper(fn)\n\u001b[1;32m    539\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m allow_trials_fmin \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(trials, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfmin\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 540\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtrials\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfmin\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    541\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    542\u001b[0m \u001b[43m        \u001b[49m\u001b[43mspace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    543\u001b[0m \u001b[43m        \u001b[49m\u001b[43malgo\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43malgo\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    544\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_evals\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_evals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    545\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    546\u001b[0m \u001b[43m        \u001b[49m\u001b[43mloss_threshold\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mloss_threshold\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    547\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_queue_len\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_queue_len\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    548\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrstate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrstate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    549\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpass_expr_memo_ctrl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpass_expr_memo_ctrl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    550\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    551\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcatch_eval_exceptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcatch_eval_exceptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    552\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_argmin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_argmin\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    553\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshow_progressbar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshow_progressbar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    554\u001b[0m \u001b[43m        \u001b[49m\u001b[43mearly_stop_fn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mearly_stop_fn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    555\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrials_save_file\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrials_save_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    556\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    558\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m trials \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    559\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(trials_save_file):\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/hyperopt/base.py:671\u001b[0m, in \u001b[0;36mTrials.fmin\u001b[0;34m(self, fn, space, algo, max_evals, timeout, loss_threshold, max_queue_len, rstate, verbose, pass_expr_memo_ctrl, catch_eval_exceptions, return_argmin, show_progressbar, early_stop_fn, trials_save_file)\u001b[0m\n\u001b[1;32m    666\u001b[0m \u001b[38;5;66;03m# -- Stop-gap implementation!\u001b[39;00m\n\u001b[1;32m    667\u001b[0m \u001b[38;5;66;03m#    fmin should have been a Trials method in the first place\u001b[39;00m\n\u001b[1;32m    668\u001b[0m \u001b[38;5;66;03m#    but for now it's still sitting in another file.\u001b[39;00m\n\u001b[1;32m    669\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfmin\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m fmin\n\u001b[0;32m--> 671\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfmin\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    672\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    673\u001b[0m \u001b[43m    \u001b[49m\u001b[43mspace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    674\u001b[0m \u001b[43m    \u001b[49m\u001b[43malgo\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43malgo\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    675\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_evals\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_evals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    676\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    677\u001b[0m \u001b[43m    \u001b[49m\u001b[43mloss_threshold\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mloss_threshold\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    678\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    679\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrstate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrstate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    680\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    681\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_queue_len\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_queue_len\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    682\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_trials_fmin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# -- prevent recursion\u001b[39;49;00m\n\u001b[1;32m    683\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpass_expr_memo_ctrl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpass_expr_memo_ctrl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    684\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcatch_eval_exceptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcatch_eval_exceptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    685\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_argmin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_argmin\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    686\u001b[0m \u001b[43m    \u001b[49m\u001b[43mshow_progressbar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshow_progressbar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    687\u001b[0m \u001b[43m    \u001b[49m\u001b[43mearly_stop_fn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mearly_stop_fn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    688\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrials_save_file\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrials_save_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    689\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/hyperopt/fmin.py:586\u001b[0m, in \u001b[0;36mfmin\u001b[0;34m(fn, space, algo, max_evals, timeout, loss_threshold, trials, rstate, allow_trials_fmin, pass_expr_memo_ctrl, catch_eval_exceptions, verbose, return_argmin, points_to_evaluate, max_queue_len, show_progressbar, early_stop_fn, trials_save_file)\u001b[0m\n\u001b[1;32m    583\u001b[0m rval\u001b[38;5;241m.\u001b[39mcatch_eval_exceptions \u001b[38;5;241m=\u001b[39m catch_eval_exceptions\n\u001b[1;32m    585\u001b[0m \u001b[38;5;66;03m# next line is where the fmin is actually executed\u001b[39;00m\n\u001b[0;32m--> 586\u001b[0m \u001b[43mrval\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexhaust\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    588\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m return_argmin:\n\u001b[1;32m    589\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(trials\u001b[38;5;241m.\u001b[39mtrials) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/hyperopt/fmin.py:364\u001b[0m, in \u001b[0;36mFMinIter.exhaust\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    362\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mexhaust\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    363\u001b[0m     n_done \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrials)\n\u001b[0;32m--> 364\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_evals\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mn_done\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mblock_until_done\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43masynchronous\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    365\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrials\u001b[38;5;241m.\u001b[39mrefresh()\n\u001b[1;32m    366\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/hyperopt/fmin.py:300\u001b[0m, in \u001b[0;36mFMinIter.run\u001b[0;34m(self, N, block_until_done)\u001b[0m\n\u001b[1;32m    297\u001b[0m     time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpoll_interval_secs)\n\u001b[1;32m    298\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    299\u001b[0m     \u001b[38;5;66;03m# -- loop over trials and do the jobs directly\u001b[39;00m\n\u001b[0;32m--> 300\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mserial_evaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    302\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrials\u001b[38;5;241m.\u001b[39mrefresh()\n\u001b[1;32m    303\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrials_save_file \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/hyperopt/fmin.py:178\u001b[0m, in \u001b[0;36mFMinIter.serial_evaluate\u001b[0;34m(self, N)\u001b[0m\n\u001b[1;32m    176\u001b[0m ctrl \u001b[38;5;241m=\u001b[39m base\u001b[38;5;241m.\u001b[39mCtrl(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrials, current_trial\u001b[38;5;241m=\u001b[39mtrial)\n\u001b[1;32m    177\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 178\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdomain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mspec\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctrl\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    179\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    180\u001b[0m     logger\u001b[38;5;241m.\u001b[39merror(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mjob exception: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mstr\u001b[39m(e))\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/hyperopt/base.py:892\u001b[0m, in \u001b[0;36mDomain.evaluate\u001b[0;34m(self, config, ctrl, attach_attachments)\u001b[0m\n\u001b[1;32m    883\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    884\u001b[0m     \u001b[38;5;66;03m# -- the \"work\" of evaluating `config` can be written\u001b[39;00m\n\u001b[1;32m    885\u001b[0m     \u001b[38;5;66;03m#    either into the pyll part (self.expr)\u001b[39;00m\n\u001b[1;32m    886\u001b[0m     \u001b[38;5;66;03m#    or the normal Python part (self.fn)\u001b[39;00m\n\u001b[1;32m    887\u001b[0m     pyll_rval \u001b[38;5;241m=\u001b[39m pyll\u001b[38;5;241m.\u001b[39mrec_eval(\n\u001b[1;32m    888\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexpr,\n\u001b[1;32m    889\u001b[0m         memo\u001b[38;5;241m=\u001b[39mmemo,\n\u001b[1;32m    890\u001b[0m         print_node_on_error\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrec_eval_print_node_on_error,\n\u001b[1;32m    891\u001b[0m     )\n\u001b[0;32m--> 892\u001b[0m     rval \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpyll_rval\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    894\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(rval, (\u001b[38;5;28mfloat\u001b[39m, \u001b[38;5;28mint\u001b[39m, np\u001b[38;5;241m.\u001b[39mnumber)):\n\u001b[1;32m    895\u001b[0m     dict_rval \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mfloat\u001b[39m(rval), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstatus\u001b[39m\u001b[38;5;124m\"\u001b[39m: STATUS_OK}\n",
      "Cell \u001b[0;32mIn[38], line 2\u001b[0m, in \u001b[0;36m<lambda>\u001b[0;34m(space)\u001b[0m\n\u001b[1;32m      1\u001b[0m trials \u001b[38;5;241m=\u001b[39m Trials()\n\u001b[0;32m----> 2\u001b[0m best_2 \u001b[38;5;241m=\u001b[39m fmin(fn \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m space: \u001b[43mhyperparameter_tuning\u001b[49m\u001b[43m(\u001b[49m\u001b[43mspace\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtrain_fold_2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43my_train_fold_2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m                                                     \u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mval_fold_2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43my_val_fold_2\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m      4\u001b[0m             space \u001b[38;5;241m=\u001b[39m options,\n\u001b[1;32m      5\u001b[0m             algo \u001b[38;5;241m=\u001b[39m tpe\u001b[38;5;241m.\u001b[39msuggest,\n\u001b[1;32m      6\u001b[0m             max_evals \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m250\u001b[39m,\n\u001b[1;32m      7\u001b[0m             trials \u001b[38;5;241m=\u001b[39m trials)\n",
      "Cell \u001b[0;32mIn[36], line 50\u001b[0m, in \u001b[0;36mhyperparameter_tuning\u001b[0;34m(space, X_train, y_train, X_test, y_test, early_stopping_rounds, metric)\u001b[0m\n\u001b[1;32m     47\u001b[0m model \u001b[38;5;241m=\u001b[39m xgb\u001b[38;5;241m.\u001b[39mXGBClassifier( \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mspace)\n\u001b[1;32m     48\u001b[0m evaluation \u001b[38;5;241m=\u001b[39m [(X_train, y_train), \n\u001b[1;32m     49\u001b[0m              (X_test, y_test)]\n\u001b[0;32m---> 50\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meval_set\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mevaluation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     52\u001b[0m score \u001b[38;5;241m=\u001b[39m metrics\u001b[38;5;241m.\u001b[39mroc_auc_score(y_test, model\u001b[38;5;241m.\u001b[39mpredict(X_test))\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m-\u001b[39mscore, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstatus\u001b[39m\u001b[38;5;124m'\u001b[39m: STATUS_OK, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m'\u001b[39m: model}\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/xgboost/core.py:620\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig\u001b[38;5;241m.\u001b[39mparameters, args):\n\u001b[1;32m    619\u001b[0m     kwargs[k] \u001b[38;5;241m=\u001b[39m arg\n\u001b[0;32m--> 620\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/xgboost/sklearn.py:1490\u001b[0m, in \u001b[0;36mXGBClassifier.fit\u001b[0;34m(self, X, y, sample_weight, base_margin, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model, sample_weight_eval_set, base_margin_eval_set, feature_weights, callbacks)\u001b[0m\n\u001b[1;32m   1462\u001b[0m (\n\u001b[1;32m   1463\u001b[0m     model,\n\u001b[1;32m   1464\u001b[0m     metric,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1469\u001b[0m     xgb_model, eval_metric, params, early_stopping_rounds, callbacks\n\u001b[1;32m   1470\u001b[0m )\n\u001b[1;32m   1471\u001b[0m train_dmatrix, evals \u001b[38;5;241m=\u001b[39m _wrap_evaluation_matrices(\n\u001b[1;32m   1472\u001b[0m     missing\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmissing,\n\u001b[1;32m   1473\u001b[0m     X\u001b[38;5;241m=\u001b[39mX,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1487\u001b[0m     feature_types\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeature_types,\n\u001b[1;32m   1488\u001b[0m )\n\u001b[0;32m-> 1490\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_Booster \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1491\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1492\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_dmatrix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1493\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_num_boosting_rounds\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1494\u001b[0m \u001b[43m    \u001b[49m\u001b[43mevals\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mevals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1495\u001b[0m \u001b[43m    \u001b[49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1496\u001b[0m \u001b[43m    \u001b[49m\u001b[43mevals_result\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mevals_result\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1497\u001b[0m \u001b[43m    \u001b[49m\u001b[43mobj\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1498\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcustom_metric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetric\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1499\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1500\u001b[0m \u001b[43m    \u001b[49m\u001b[43mxgb_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1501\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1504\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobjective):\n\u001b[1;32m   1505\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobjective \u001b[38;5;241m=\u001b[39m params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mobjective\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/xgboost/core.py:620\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig\u001b[38;5;241m.\u001b[39mparameters, args):\n\u001b[1;32m    619\u001b[0m     kwargs[k] \u001b[38;5;241m=\u001b[39m arg\n\u001b[0;32m--> 620\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/xgboost/training.py:186\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, custom_metric)\u001b[0m\n\u001b[1;32m    184\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m    185\u001b[0m     bst\u001b[38;5;241m.\u001b[39mupdate(dtrain, i, obj)\n\u001b[0;32m--> 186\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mcb_container\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mafter_iteration\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbst\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevals\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    187\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m    189\u001b[0m bst \u001b[38;5;241m=\u001b[39m cb_container\u001b[38;5;241m.\u001b[39mafter_training(bst)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/xgboost/callback.py:240\u001b[0m, in \u001b[0;36mCallbackContainer.after_iteration\u001b[0;34m(self, model, epoch, dtrain, evals)\u001b[0m\n\u001b[1;32m    238\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _, name \u001b[38;5;129;01min\u001b[39;00m evals:\n\u001b[1;32m    239\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m name\u001b[38;5;241m.\u001b[39mfind(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m-\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDataset name should not contain `-`\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m--> 240\u001b[0m score: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meval_set\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevals\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmetric\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_output_margin\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    241\u001b[0m splited \u001b[38;5;241m=\u001b[39m score\u001b[38;5;241m.\u001b[39msplit()[\u001b[38;5;241m1\u001b[39m:]  \u001b[38;5;66;03m# into datasets\u001b[39;00m\n\u001b[1;32m    242\u001b[0m \u001b[38;5;66;03m# split up `test-error:0.1234`\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/xgboost/core.py:1989\u001b[0m, in \u001b[0;36mBooster.eval_set\u001b[0;34m(self, evals, iteration, feval, output_margin)\u001b[0m\n\u001b[1;32m   1986\u001b[0m evnames \u001b[38;5;241m=\u001b[39m c_array(ctypes\u001b[38;5;241m.\u001b[39mc_char_p, [c_str(d[\u001b[38;5;241m1\u001b[39m]) \u001b[38;5;28;01mfor\u001b[39;00m d \u001b[38;5;129;01min\u001b[39;00m evals])\n\u001b[1;32m   1987\u001b[0m msg \u001b[38;5;241m=\u001b[39m ctypes\u001b[38;5;241m.\u001b[39mc_char_p()\n\u001b[1;32m   1988\u001b[0m _check_call(\n\u001b[0;32m-> 1989\u001b[0m     \u001b[43m_LIB\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mXGBoosterEvalOneIter\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1990\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1991\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mc_int\u001b[49m\u001b[43m(\u001b[49m\u001b[43miteration\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1992\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdmats\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1993\u001b[0m \u001b[43m        \u001b[49m\u001b[43mevnames\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1994\u001b[0m \u001b[43m        \u001b[49m\u001b[43mc_bst_ulong\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mevals\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1995\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbyref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmsg\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1996\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1997\u001b[0m )\n\u001b[1;32m   1998\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m msg\u001b[38;5;241m.\u001b[39mvalue \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1999\u001b[0m res \u001b[38;5;241m=\u001b[39m msg\u001b[38;5;241m.\u001b[39mvalue\u001b[38;5;241m.\u001b[39mdecode()  \u001b[38;5;66;03m# pylint: disable=no-member\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "trials = Trials()\n",
    "best_2 = fmin(fn = lambda space: hyperparameter_tuning(space, X_train = train_fold_2, y_train = y_train_fold_2,\n",
    "                                                     X_test = val_fold_2, y_test = y_val_fold_2),\n",
    "            space = options,\n",
    "            algo = tpe.suggest,\n",
    "            max_evals = 250,\n",
    "            trials = trials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8999ca72",
   "metadata": {},
   "outputs": [],
   "source": [
    "trials = Trials()\n",
    "best_3 = fmin(fn = lambda space: hyperparameter_tuning(space, X_train = train_fold_3, y_train = y_train_fold_3,\n",
    "                                                     X_test = val_fold_3, y_test = y_val_fold_3),\n",
    "            space = options,\n",
    "            algo = tpe.suggest,\n",
    "            max_evals = 250,\n",
    "            trials = trials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "id": "08755e09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'colsample_bytree': 0.9995470529550116,\n",
       " 'gamma': 0.2494451565928528,\n",
       " 'learning_rate': 0.8890758684579567,\n",
       " 'max_delta_step': 6.0,\n",
       " 'max_depth': 4.0,\n",
       " 'min_child_weight': 4.622430255347508,\n",
       " 'n_estimators': 6,\n",
       " 'reg_alpha': 8.533926801209859,\n",
       " 'reg_lambda': 7.312695892505459,\n",
       " 'scale_pos_weight': 54.92197348455757,\n",
       " 'subsample': 0.6036661031025599}"
      ]
     },
     "execution_count": 340,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "id": "9262cbfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_3 = {'colsample_bytree': 0.7927785613988597,\n",
    " 'gamma': 3.4447052693725935,\n",
    " 'learning_rate': 0.45758781828500494,\n",
    " 'max_delta_step': 5,\n",
    " 'max_depth': 7,\n",
    " 'min_child_weight': 0.13646369191256574,\n",
    " 'n_estimators': 14,\n",
    " 'reg_alpha': 0.013744605066518228,\n",
    " 'reg_lambda': 3.6663350252589004,\n",
    " 'scale_pos_weight': 31.545969624928553,\n",
    " 'subsample': 0.7471737600445566}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "id": "ea480aaf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-20 {color: black;}#sk-container-id-20 pre{padding: 0;}#sk-container-id-20 div.sk-toggleable {background-color: white;}#sk-container-id-20 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-20 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-20 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-20 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-20 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-20 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-20 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-20 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-20 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-20 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-20 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-20 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-20 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-20 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-20 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-20 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-20 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-20 div.sk-item {position: relative;z-index: 1;}#sk-container-id-20 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-20 div.sk-item::before, #sk-container-id-20 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-20 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-20 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-20 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-20 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-20 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-20 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-20 div.sk-label-container {text-align: center;}#sk-container-id-20 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-20 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-20\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=0.7927785613988597, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=3.4447052693725935, gpu_id=None, grow_policy=None,\n",
       "              importance_type=None, interaction_constraints=None,\n",
       "              learning_rate=0.45758781828500494, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None, max_delta_step=5,\n",
       "              max_depth=7, max_leaves=None,\n",
       "              min_child_weight=0.13646369191256574, missing=nan,\n",
       "              monotone_constraints=None, n_estimators=14, n_jobs=None,\n",
       "              num_parallel_tree=None, predictor=None, random_state=None, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-20\" type=\"checkbox\" checked><label for=\"sk-estimator-id-20\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=0.7927785613988597, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=3.4447052693725935, gpu_id=None, grow_policy=None,\n",
       "              importance_type=None, interaction_constraints=None,\n",
       "              learning_rate=0.45758781828500494, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None, max_delta_step=5,\n",
       "              max_depth=7, max_leaves=None,\n",
       "              min_child_weight=0.13646369191256574, missing=nan,\n",
       "              monotone_constraints=None, n_estimators=14, n_jobs=None,\n",
       "              num_parallel_tree=None, predictor=None, random_state=None, ...)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=0.7927785613988597, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=3.4447052693725935, gpu_id=None, grow_policy=None,\n",
       "              importance_type=None, interaction_constraints=None,\n",
       "              learning_rate=0.45758781828500494, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None, max_delta_step=5,\n",
       "              max_depth=7, max_leaves=None,\n",
       "              min_child_weight=0.13646369191256574, missing=nan,\n",
       "              monotone_constraints=None, n_estimators=14, n_jobs=None,\n",
       "              num_parallel_tree=None, predictor=None, random_state=None, ...)"
      ]
     },
     "execution_count": 325,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model = xgb.XGBClassifier(**best_3)\n",
    "best_model.fit(X_train_new, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "id": "d3dbfba3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9926240500670541"
      ]
     },
     "execution_count": 329,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model.score(X_train_new, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cd274403",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(['Motor_DispEn', 'Motor_Gamma', 'Soma_DispEn', 'Soma_HFD', 'Soma_Gamma',\n",
    "       'Soma_Theta', 'Visual_DispEn', 'Visual_Hurst', 'Vis_Gamma',\n",
    "       'Mot_CC_Right', 'Mot_CC_Left', 'Som_CC_Right', 'Som_CC_Left',\n",
    "       'Vis_CC_Right', 'Som_PL_Left'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "id": "c9386801",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Feature shape mismatch, expected: 72, got 48",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[330], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mbest_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscore\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_fold_1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train_fold_1\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(best_model\u001b[38;5;241m.\u001b[39mscore(train_fold_2, y_train_fold_2))\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(best_model\u001b[38;5;241m.\u001b[39mscore(train_fold_3, y_train_fold_3))\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/base.py:705\u001b[0m, in \u001b[0;36mClassifierMixin.score\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    680\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    681\u001b[0m \u001b[38;5;124;03mReturn the mean accuracy on the given test data and labels.\u001b[39;00m\n\u001b[1;32m    682\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    701\u001b[0m \u001b[38;5;124;03m    Mean accuracy of ``self.predict(X)`` w.r.t. `y`.\u001b[39;00m\n\u001b[1;32m    702\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    703\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m accuracy_score\n\u001b[0;32m--> 705\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m accuracy_score(y, \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m, sample_weight\u001b[38;5;241m=\u001b[39msample_weight)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/xgboost/sklearn.py:1525\u001b[0m, in \u001b[0;36mXGBClassifier.predict\u001b[0;34m(self, X, output_margin, ntree_limit, validate_features, base_margin, iteration_range)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict\u001b[39m(\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1517\u001b[0m     X: ArrayLike,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1522\u001b[0m     iteration_range: Optional[Tuple[\u001b[38;5;28mint\u001b[39m, \u001b[38;5;28mint\u001b[39m]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1523\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m np\u001b[38;5;241m.\u001b[39mndarray:\n\u001b[1;32m   1524\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(verbosity\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbosity):\n\u001b[0;32m-> 1525\u001b[0m         class_probs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1526\u001b[0m \u001b[43m            \u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1527\u001b[0m \u001b[43m            \u001b[49m\u001b[43moutput_margin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_margin\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1528\u001b[0m \u001b[43m            \u001b[49m\u001b[43mntree_limit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mntree_limit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[43m            \u001b[49m\u001b[43mvalidate_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidate_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1530\u001b[0m \u001b[43m            \u001b[49m\u001b[43mbase_margin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbase_margin\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1531\u001b[0m \u001b[43m            \u001b[49m\u001b[43miteration_range\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43miteration_range\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1532\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1533\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m output_margin:\n\u001b[1;32m   1534\u001b[0m             \u001b[38;5;66;03m# If output_margin is active, simply return the scores\u001b[39;00m\n\u001b[1;32m   1535\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m class_probs\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/xgboost/sklearn.py:1114\u001b[0m, in \u001b[0;36mXGBModel.predict\u001b[0;34m(self, X, output_margin, ntree_limit, validate_features, base_margin, iteration_range)\u001b[0m\n\u001b[1;32m   1112\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_can_use_inplace_predict():\n\u001b[1;32m   1113\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1114\u001b[0m         predts \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_booster\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minplace_predict\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1115\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1116\u001b[0m \u001b[43m            \u001b[49m\u001b[43miteration_range\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43miteration_range\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1117\u001b[0m \u001b[43m            \u001b[49m\u001b[43mpredict_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmargin\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43moutput_margin\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mvalue\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1118\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmissing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmissing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1119\u001b[0m \u001b[43m            \u001b[49m\u001b[43mbase_margin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbase_margin\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1120\u001b[0m \u001b[43m            \u001b[49m\u001b[43mvalidate_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidate_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1121\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1122\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m _is_cupy_array(predts):\n\u001b[1;32m   1123\u001b[0m             \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcupy\u001b[39;00m  \u001b[38;5;66;03m# pylint: disable=import-error\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/xgboost/core.py:2269\u001b[0m, in \u001b[0;36mBooster.inplace_predict\u001b[0;34m(self, data, iteration_range, predict_type, missing, validate_features, base_margin, strict_shape)\u001b[0m\n\u001b[1;32m   2265\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m   2266\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`shape` attribute is required when `validate_features` is True.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2267\u001b[0m         )\n\u001b[1;32m   2268\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(data\u001b[38;5;241m.\u001b[39mshape) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_features() \u001b[38;5;241m!=\u001b[39m data\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]:\n\u001b[0;32m-> 2269\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   2270\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFeature shape mismatch, expected: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_features()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2271\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgot \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdata\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2272\u001b[0m         )\n\u001b[1;32m   2274\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m   2275\u001b[0m     _array_interface,\n\u001b[1;32m   2276\u001b[0m     _is_cudf_df,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2279\u001b[0m     _transform_pandas_df,\n\u001b[1;32m   2280\u001b[0m )\n\u001b[1;32m   2282\u001b[0m enable_categorical \u001b[38;5;241m=\u001b[39m _has_categorical(\u001b[38;5;28mself\u001b[39m, data)\n",
      "\u001b[0;31mValueError\u001b[0m: Feature shape mismatch, expected: 72, got 48"
     ]
    }
   ],
   "source": [
    "print(best_model.score(train_fold_1, y_train_fold_1))\n",
    "print(best_model.score(train_fold_2, y_train_fold_2))\n",
    "print(best_model.score(train_fold_3, y_train_fold_3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "id": "1c48e511",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7181889149102264"
      ]
     },
     "execution_count": 327,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model.score(X_test_new, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "bfce4e89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3bb4adbcdf174b079eff6914c72b3dd8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48 attributes confirmed important: ['hfd_E1', 'theta_E1', 'plv_F3_C3', 'plv_O1_M2', 'beta_F3', 'beta_C3', 'beta_E2', 'theta_O1', 'alpha_C3', 'beta_E1', 'cc_E1_E2', 'theta_M2', 'cc_E1_M2', 'plv_C3_O1', 'plv_E1_F3', 'cc_E1_F3', 'plv_F3_M2', 'plv_E2_M2', 'plv_E1_E2', 'delta_M2', 'hfd_E2', 'alpha_E1', 'cc_E1_C3', 'hfd_F3', 'alpha_E2', 'plv_E2_F3', 'plv_F3_O1', 'beta_M2', 'cc_F3_C3', 'cc_E1_O1', 'theta_E2', 'alpha_M2', 'cc_O1_M2', 'plv_E1_O1', 'cc_C3_M2', 'cc_E2_O1', 'cc_F3_M2', 'plv_C3_M2', 'entr_C3', 'plv_E2_C3', 'theta_C3', 'cc_E2_F3', 'hfd_M2', 'cc_E2_C3', 'plv_E2_O1', 'cc_C3_O1', 'cc_F3_O1', 'beta_O1']\n",
      "16 attributes confirmed unimportant: ['hfd_C3', 'delta_F3', 'entr_E2', 'hurst_E2', 'hurst_M2', 'alpha_F3', 'hurst_C3', 'alpha_O1', 'delta_E2', 'delta_E1', 'delta_C3', 'hurst_F3', 'plv_E1_M2', 'delta_O1', 'plv_E1_C3', 'theta_F3']\n",
      "8 tentative attributes remains: ['hurst_E1', 'entr_F3', 'entr_M2', 'hurst_O1', 'entr_E1', 'cc_E2_M2', 'hfd_O1', 'entr_O1']\n"
     ]
    }
   ],
   "source": [
    "estimator_borutashap=XGBClassifier(n_jobs = -1,\n",
    "                                           random_state=42,\n",
    "                                           max_depth=4)\n",
    "borutashap = BorutaShap(model = estimator_borutashap,\n",
    "                            importance_measure = 'shap',\n",
    "                            classification = True)\n",
    "borutashap.fit(X = X_train_new, y = y_train, \n",
    "                   n_trials = 250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "10862d0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "borutashap.plot(X_size=12, figsize=(12,8),\n",
    "            y_scale='log', which_features='rejected')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
